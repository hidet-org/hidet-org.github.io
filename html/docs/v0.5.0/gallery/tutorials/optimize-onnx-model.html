

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-406WJTRD8C"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-406WJTRD8C');
    </script>
    
    <title>Optimize ONNX Model &#8212; Hidet Documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'gallery/tutorials/optimize-onnx-model';</script>
    <link rel="icon" href="../../_static/favicon.svg"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Introduction" href="../../hidet-script/index.html" />
    <link rel="prev" title="Optimize PyTorch Model" href="optimize-pytorch-model.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.svg" class="logo__image only-light" alt="Hidet Documentation - Home"/>
    <img src="../../_static/logo.svg" class="logo__image only-dark pst-js-only" alt="Hidet Documentation - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../getting-started/install.html">Installation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../getting-started/build-from-source.html">Build from source</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../getting-started/quick-start.html">Quick Start</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="optimize-pytorch-model.html">Optimize PyTorch Model</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Optimize ONNX Model</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Hidet Script</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../hidet-script/index.html">Introduction</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../hidet-script/examples/index.html">Examples</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../hidet-script/0-hello-world.html">Hello World!</a></li>
<li class="toctree-l2"><a class="reference internal" href="../hidet-script/1-scalar-addition.html">Scalar Addition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../hidet-script/2-vector-addition.html">Vector Addition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../hidet-script/3-kernel-functions.html">Kernel Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../hidet-script/4-naive-matmul.html">Naive Matrix Multiplication</a></li>
<li class="toctree-l2"><a class="reference internal" href="../hidet-script/5-efficient-matmul.html">More Efficient Matrix Multiplication</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../hidet-script/reference/index.html">Reference</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../hidet-script/reference/1-type-system.html">Type System</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../hidet-script/reference/2-expression.html">Expressions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../hidet-script/reference/3-statement.html">Statements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../hidet-script/reference/4-function.html">Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../hidet-script/reference/5-module.html">Module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../hidet-script/reference/6-cuda-specific.html">CUDA Specifics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../hidet-script/reference/7-cpu-specific.html">CPU Specifics</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Developer Guide</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../developer-guides/add-torch-operator-mapping.html">Add PyTorch Operator Mapping</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../how-to-guides/add-new-operator/index.html">Add New Operator</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../developer-guides/add-new-operator-compute-definition.html">Define Operator Computation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../developer-guides/add-new-operator-rule-based.html">Using Rule-based Scheduling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../developer-guides/add-new-operator-template-based.html">Using Template-based Scheduling</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../developer-guides/add-operator-resolve-rule.html">Add Operator Resolve Rule</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer-guides/add-subgraph-rewrite-rule.html">Add Sub-Graph Rewrite Rule</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../developer-guides/contributing.html">Contributing</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../notes/operator-cache.html">Operator Cache</a></li>
<li class="toctree-l1"><a class="reference internal" href="../how-to-guides/visualize-flow-graph.html">Visualize Flow Graph</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../python_api/index.html">Python API</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../python_api/root.html">hidet</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../python_api/option.html">hidet.option</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../python_api/cuda.html">hidet.cuda</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../python_api/tensor.html">hidet.Tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../python_api/data_types.html">hidet.dtypes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../python_api/drivers.html">hidet.drivers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../python_api/ops/index.html">hidet.ops</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../python_api/graph/index.html">hidet.graph</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../python_api/graph/frontend/index.html">hidet.graph.frontend</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../../python_api/graph/frontend/onnx.html">hidet.graph.frontend.onnx</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../python_api/graph/frontend/torch.html">hidet.graph.frontend.torch</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../python_api/graph/transforms/index.html">hidet.graph.transforms</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../../python_api/graph/transforms/subgraph_rewrite.html">Sub-graph Rewrite Pass</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../python_api/graph/transforms/resolve_variant.html">Resolve Operator Pass</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../python_api/runtime/index.html">hidet.runtime</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../python_api/ffi/index.html">hidet.ffi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../python_api/utils/index.html">hidet.utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../python_api/testing/index.html">hidet.testing</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../genindex.html">Index</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/hidet-org/hidet" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/gallery/tutorials/optimize-onnx-model.rst" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.rst</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Optimize ONNX Model</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preparation-of-onnx-model">Preparation of ONNX model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#load-the-onnx-model-with-hidet">Load the onnx model with Hidet</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#imperatively-run-the-model">Imperatively run the model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#trace-the-model-and-run">Trace the model and run</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optimize-flowgraph">Optimize FlowGraph</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-gallery-tutorials-optimize-onnx-model-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="optimize-onnx-model">
<span id="sphx-glr-gallery-tutorials-optimize-onnx-model-py"></span><span id="id1"></span><h1>Optimize ONNX Model<a class="headerlink" href="#optimize-onnx-model" title="Permalink to this heading"><span>¶</span></a></h1>
<p>This tutorial walks through the steps to run a model in <a class="reference external" href="https://onnx.ai/">ONNX format</a> with Hidet.
The ResNet50 onnx model exported from PyTorch model zoo would be used as an example.</p>
<section id="preparation-of-onnx-model">
<h2>Preparation of ONNX model<a class="headerlink" href="#preparation-of-onnx-model" title="Permalink to this heading"><span>¶</span></a></h2>
<p>We first export the pretrained resnet50 model from torchvision model zoo to an onnx model, using
<a class="reference external" href="https://pytorch.org/docs/stable/onnx_torchscript.html#torch.onnx.export" title="(in PyTorch v2.6)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.onnx.export()</span></code></a>. After exporting, there will be a file named <code class="docutils literal notranslate"><span class="pre">resnet50.onnx</span></code>
under current working directory.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="c1"># the path to save the onnx model</span>
<span class="n">onnx_path</span> <span class="o">=</span> <span class="s1">&#39;./resnet50.onnx&#39;</span>

<span class="c1"># load pretrained resnet50 and create a random input</span>
<span class="n">torch_model</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/hub.html#torch.hub.load" title="torch.hub.load" class="sphx-glr-backref-module-torch-hub sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">hub</span><span class="o">.</span><span class="n">load</span></a><span class="p">(</span><span class="s1">&#39;pytorch/vision:v0.9.0&#39;</span><span class="p">,</span> <span class="s1">&#39;resnet50&#39;</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">torch_model</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.cuda" title="torch.nn.Module.cuda" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">torch_model</span><span class="o">.</span><span class="n">cuda</span></a><span class="p">()</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch_data</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">])</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="c1"># export the pytorch model to onnx model &#39;resnet50.onnx&#39;</span>
<a href="https://pytorch.org/docs/stable/onnx_torchscript.html#torch.onnx.export" title="torch.onnx.export" class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">export</span></a><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">torch_model</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch_data</span></a><span class="p">,</span>
    <span class="n">f</span><span class="o">=</span><span class="n">onnx_path</span><span class="p">,</span>
    <span class="n">input_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">],</span>
    <span class="n">output_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;output&#39;</span><span class="p">],</span>
    <span class="n">dynamic_axes</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;data&#39;</span><span class="p">:</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">},</span> <span class="s1">&#39;output&#39;</span><span class="p">:</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">}},</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1">: </span><span class="si">{:.1f}</span><span class="s1"> MiB&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">onnx_path</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">getsize</span><span class="p">(</span><span class="n">onnx_path</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="mi">20</span><span class="p">)))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>./resnet50.onnx: 97.4 MiB
</pre></div>
</div>
<p>Before going further, we first measure the latency of reset50 directly using PyTorch for inference.
The <code class="xref py py-func docutils literal notranslate"><span class="pre">benchmark_func()</span></code> function runs the given function multiple times to
get the median latency.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">hidet.utils.benchmark</span><span class="w"> </span><span class="kn">import</span> <span class="n">benchmark_func</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;PyTorch: </span><span class="si">{:.3f}</span><span class="s1"> ms&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">benchmark_func</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">torch_model</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch_data</span></a><span class="p">))))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>PyTorch: 5.005 ms
</pre></div>
</div>
</section>
<section id="load-the-onnx-model-with-hidet">
<h2>Load the onnx model with Hidet<a class="headerlink" href="#load-the-onnx-model-with-hidet" title="Permalink to this heading"><span>¶</span></a></h2>
<p>To run the onnx model, we should first load the model with <a class="reference internal" href="../../python_api/graph/frontend/onnx.html#hidet.graph.frontend.from_onnx" title="hidet.graph.frontend.from_onnx"><code class="xref py py-func docutils literal notranslate"><span class="pre">hidet.graph.frontend.from_onnx()</span></code></a> function by giving
the path to the onnx model. This function returns callable object, which applies all operators in the onnx model to
the input argument and returns the output tensor(s). The onnx model can be dynamic-shaped (e.g., in this example, the
batch size is dynamic).</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">hidet</span>

<span class="c1"># load onnx model &#39;resnet50.onnx&#39;</span>
<span class="n">hidet_onnx_module</span> <span class="o">=</span> <span class="n">hidet</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">frontend</span><span class="o">.</span><span class="n">from_onnx</span><span class="p">(</span><span class="n">onnx_path</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Input names:&#39;</span><span class="p">,</span> <span class="n">hidet_onnx_module</span><span class="o">.</span><span class="n">input_names</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Output names: &#39;</span><span class="p">,</span> <span class="n">hidet_onnx_module</span><span class="o">.</span><span class="n">output_names</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Input names: [&#39;data&#39;]
Output names:  [&#39;output&#39;]
</pre></div>
</div>
</section>
<section id="imperatively-run-the-model">
<h2>Imperatively run the model<a class="headerlink" href="#imperatively-run-the-model" title="Permalink to this heading"><span>¶</span></a></h2>
<p>To run the model, we first create a hidet tensor from torch tensor with <a class="reference internal" href="../../python_api/root.html#hidet.from_torch" title="hidet.from_torch"><code class="xref py py-func docutils literal notranslate"><span class="pre">hidet.from_torch()</span></code></a>. We directly
call <code class="docutils literal notranslate"><span class="pre">hidet_onnx_module</span></code> to apply the operators in loaded onnx model to the given input tensor and get the output
tensor.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># create a hidet tensor from pytorch tensor.</span>
<span class="n">data</span><span class="p">:</span> <span class="n">hidet</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">hidet</span><span class="o">.</span><span class="n">from_torch</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch_data</span></a><span class="p">)</span>

<span class="c1"># apply the operators in onnx model to given &#39;data&#39; input tensor</span>
<span class="n">output</span><span class="p">:</span> <span class="n">hidet</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">hidet_onnx_module</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># check the output of hidet with pytorch</span>
<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch_output</span></a> <span class="o">=</span> <span class="n">torch_model</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch_data</span></a><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
<a href="https://numpy.org/doc/stable/reference/generated/numpy.testing.assert_allclose.html#numpy.testing.assert_allclose" title="numpy.testing.assert_allclose" class="sphx-glr-backref-module-numpy-testing sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span></a><span class="p">(</span>
    <span class="n">actual</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">desired</span><span class="o">=</span><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch_output</span></a><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-2</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="trace-the-model-and-run">
<h2>Trace the model and run<a class="headerlink" href="#trace-the-model-and-run" title="Permalink to this heading"><span>¶</span></a></h2>
<p>A more efficient way to run the model is to first trace the execution and get the static computation graph of the deep
learning model. We can use <a class="reference internal" href="../../python_api/root.html#hidet.symbol_like" title="hidet.symbol_like"><code class="xref py py-func docutils literal notranslate"><span class="pre">hidet.symbol_like()</span></code></a> to create a symbol tensor. We can get the symbol tensor output by
running the model with the symbol tensor as input. The output is a symbol tensor that contains all information of how
it is derived. We can use <a class="reference internal" href="../../python_api/root.html#hidet.trace_from" title="hidet.trace_from"><code class="xref py py-func docutils literal notranslate"><span class="pre">hidet.trace_from()</span></code></a> to create the static computation graph from the symbol output
tensor. In hidet, we use <a class="reference internal" href="../../python_api/graph/index.html#hidet.graph.FlowGraph" title="hidet.graph.FlowGraph"><code class="xref py py-class docutils literal notranslate"><span class="pre">hidet.graph.FlowGraph</span></code></a> to represent such a computation graph, and it is also the
basic unit of graph-level optimizations.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">symbol_data</span> <span class="o">=</span> <span class="n">hidet</span><span class="o">.</span><span class="n">symbol_like</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">symbol_output</span> <span class="o">=</span> <span class="n">hidet_onnx_module</span><span class="p">(</span><span class="n">symbol_data</span><span class="p">)</span>
<span class="n">graph</span><span class="p">:</span> <span class="n">hidet</span><span class="o">.</span><span class="n">FlowGraph</span> <span class="o">=</span> <span class="n">hidet</span><span class="o">.</span><span class="n">trace_from</span><span class="p">(</span><span class="n">symbol_output</span><span class="p">)</span>
</pre></div>
</div>
<p>We can directly call the flow graph to run it. A more efficient way is to create a
CUDA Graph according to the flow graph and run the CUDA Graph.</p>
<div class="margin admonition note">
<p class="admonition-title">Note</p>
<p>The <a class="reference external" href="https://developer.nvidia.com/blog/cuda-graphs/">CUDA Graph</a> is a more efficient
way to submit workload to NVIDIA GPU, it eliminates most of the framework-side overhead.</p>
</div>
<p>We use <a class="reference internal" href="../../python_api/graph/index.html#hidet.graph.FlowGraph.cuda_graph" title="hidet.graph.FlowGraph.cuda_graph"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cuda_graph()</span></code></a> method of a <a class="reference internal" href="../../python_api/graph/index.html#hidet.graph.FlowGraph" title="hidet.graph.FlowGraph"><code class="xref py py-class docutils literal notranslate"><span class="pre">FlowGraph</span></code></a> to create a
<a class="reference internal" href="../../python_api/cuda.html#hidet.cuda.graph.CudaGraph" title="hidet.cuda.graph.CudaGraph"><code class="xref py py-class docutils literal notranslate"><span class="pre">CudaGraph</span></code></a>.
Then, we use <a class="reference internal" href="../../python_api/cuda.html#hidet.cuda.graph.CudaGraph.run" title="hidet.cuda.graph.CudaGraph.run"><code class="xref py py-meth docutils literal notranslate"><span class="pre">run()</span></code></a> method to run the cuda graph.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">bench_hidet_graph</span><span class="p">(</span><span class="n">graph</span><span class="p">:</span> <span class="n">hidet</span><span class="o">.</span><span class="n">FlowGraph</span><span class="p">):</span>
    <span class="n">cuda_graph</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">cuda_graph</span><span class="p">()</span>
    <span class="p">(</span><span class="n">output</span><span class="p">,)</span> <span class="o">=</span> <span class="n">cuda_graph</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">data</span><span class="p">])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.testing.assert_allclose.html#numpy.testing.assert_allclose" title="numpy.testing.assert_allclose" class="sphx-glr-backref-module-numpy-testing sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span></a><span class="p">(</span>
        <span class="n">actual</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">desired</span><span class="o">=</span><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch_output</span></a><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">5e-2</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">5e-2</span>
    <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  Hidet: </span><span class="si">{:.3f}</span><span class="s1"> ms&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">benchmark_func</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">cuda_graph</span><span class="o">.</span><span class="n">run</span><span class="p">())))</span>


<span class="n">bench_hidet_graph</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Parallel build:   0%|                                    | 0/56 [00:00&lt;?, ?it/s]
Parallel build:   2%|▌                           | 1/56 [00:00&lt;00:31,  1.73it/s]
Parallel build:   4%|█                           | 2/56 [00:03&lt;01:47,  2.00s/it]
Parallel build:  96%|██████████████████████████ | 54/56 [00:04&lt;00:00, 14.52it/s]
Parallel build: 100%|███████████████████████████| 56/56 [00:04&lt;00:00, 11.32it/s]
  Hidet: 6.617 ms
</pre></div>
</div>
</section>
<section id="optimize-flowgraph">
<h2>Optimize FlowGraph<a class="headerlink" href="#optimize-flowgraph" title="Permalink to this heading"><span>¶</span></a></h2>
<p>To optimize the model, we set the level of operator schedule space to 2 with <a class="reference internal" href="../../python_api/option.html#hidet.option.search_space" title="hidet.option.search_space"><code class="xref py py-func docutils literal notranslate"><span class="pre">hidet.option.search_space()</span></code></a>. We also
conduct graph level optimizations with <a class="reference internal" href="../../python_api/graph/index.html#hidet.graph.optimize" title="hidet.graph.optimize"><code class="xref py py-func docutils literal notranslate"><span class="pre">hidet.graph.optimize()</span></code></a>.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the search space level for kernel tuning. By default, the search space level is 0, which means no kernel tuning.</span>
<span class="c1"># There are three choices: 0, 1, and 2. The higher the level, the better performance but the longer compilation time.</span>
<span class="n">hidet</span><span class="o">.</span><span class="n">option</span><span class="o">.</span><span class="n">search_space</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># optimize the flow graph, such as operator fusion</span>
<span class="k">with</span> <span class="n">hidet</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">PassContext</span><span class="p">()</span> <span class="k">as</span> <span class="n">ctx</span><span class="p">:</span>
    <span class="n">ctx</span><span class="o">.</span><span class="n">save_graph_instrument</span><span class="p">(</span><span class="s1">&#39;./outs/graphs&#39;</span><span class="p">)</span>
    <span class="n">graph_opt</span><span class="p">:</span> <span class="n">hidet</span><span class="o">.</span><span class="n">FlowGraph</span> <span class="o">=</span> <span class="n">hidet</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>

<span class="n">bench_hidet_graph</span><span class="p">(</span><span class="n">graph_opt</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Parallel build:   0%|                                    | 0/32 [00:00&lt;?, ?it/s]
Parallel build:   3%|▉                           | 1/32 [00:05&lt;02:36,  5.04s/it]
Parallel build:  28%|███████▉                    | 9/32 [00:05&lt;00:10,  2.14it/s]
Parallel build:  38%|██████████▏                | 12/32 [00:06&lt;00:07,  2.73it/s]
Parallel build:  56%|███████████████▏           | 18/32 [00:09&lt;00:06,  2.15it/s]
Parallel build:  59%|████████████████           | 19/32 [00:09&lt;00:05,  2.28it/s]
Parallel build:  81%|█████████████████████▉     | 26/32 [00:09&lt;00:01,  4.32it/s]
Parallel build:  91%|████████████████████████▍  | 29/32 [00:10&lt;00:00,  5.07it/s]
Parallel build:  97%|██████████████████████████▏| 31/32 [00:10&lt;00:00,  5.78it/s]
Parallel build: 100%|███████████████████████████| 32/32 [00:10&lt;00:00,  3.07it/s]
  Hidet: 3.810 ms
</pre></div>
</div>
<p>When we search in space 2, we can have the following numbers on RTX 4090:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>PyTorch: 1.806 ms (eager mode)
  Hidet: 3.477 ms (no optimization)
  Hidet: 0.841 ms (optimization and search space 2)
</pre></div>
</div>
</section>
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this heading"><span>¶</span></a></h2>
<p>Hidet is a DNN inference framework that accepts ONNX model. It conducts both graph-level and operator-level
optimizations. We follow the following steps to run an ONNX model in Hidet:</p>
<ol class="arabic simple">
<li><p>Load the model with <a class="reference internal" href="../../python_api/graph/frontend/onnx.html#hidet.graph.frontend.from_onnx" title="hidet.graph.frontend.from_onnx"><code class="xref py py-func docutils literal notranslate"><span class="pre">hidet.graph.frontend.from_onnx()</span></code></a>.</p></li>
<li><p>Run the model with symbolic inputs, and use <a class="reference internal" href="../../python_api/root.html#hidet.trace_from" title="hidet.trace_from"><code class="xref py py-func docutils literal notranslate"><span class="pre">hidet.trace_from()</span></code></a> to create the <a class="reference internal" href="../../python_api/graph/index.html#hidet.graph.FlowGraph" title="hidet.graph.FlowGraph"><code class="xref py py-class docutils literal notranslate"><span class="pre">hidet.graph.FlowGraph</span></code></a>.</p></li>
<li><p>Create a <a class="reference internal" href="../../python_api/cuda.html#hidet.cuda.graph.CudaGraph" title="hidet.cuda.graph.CudaGraph"><code class="xref py py-class docutils literal notranslate"><span class="pre">hidet.cuda.graph.CudaGraph</span></code></a> using <a class="reference internal" href="../../python_api/graph/index.html#hidet.graph.FlowGraph.cuda_graph" title="hidet.graph.FlowGraph.cuda_graph"><code class="xref py py-func docutils literal notranslate"><span class="pre">hidet.graph.FlowGraph.cuda_graph()</span></code></a>.</p></li>
<li><p>Run the cuda graph.</p></li>
</ol>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (1 minutes 19.593 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-gallery-tutorials-optimize-onnx-model-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/8fa604e9dc111eca8379960b077310f7/optimize-onnx-model.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">optimize-onnx-model.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/cde6a7baa459ac1401413d80cc3f7a36/optimize-onnx-model.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">optimize-onnx-model.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/17131197e615394610bd415c7fc3a091/optimize-onnx-model.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">optimize-onnx-model.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="optimize-pytorch-model.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Optimize PyTorch Model</p>
      </div>
    </a>
    <a class="right-next"
       href="../../hidet-script/index.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Introduction</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preparation-of-onnx-model">Preparation of ONNX model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#load-the-onnx-model-with-hidet">Load the onnx model with Hidet</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#imperatively-run-the-model">Imperatively run the model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#trace-the-model-and-run">Trace the model and run</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optimize-flowgraph">Optimize FlowGraph</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Hidet Team
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025, Hidet Authors.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>