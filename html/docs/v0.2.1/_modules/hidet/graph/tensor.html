
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-406WJTRD8C"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-406WJTRD8C');
    </script>
    
    <title>hidet.graph.tensor &#8212; Hidet Documentation</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-rendered-html.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <link rel="shortcut icon" href="../../../_static/favicon.svg"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../../_static/logo.svg" class="logo" alt="logo">
      
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Getting Started
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../getting-started/install.html">
   Installation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../getting-started/build-from-source.html">
     Build from source
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../gallery/getting-started/quick-start.html">
   Quick Start
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tutorials
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../gallery/tutorials/optimize-pytorch-model.html">
   Optimize PyTorch Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../gallery/tutorials/run-onnx-model.html">
   Optimize ONNX Model
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  How-to Guide
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../how-to-guides/add-new-operator/index.html">
   Add New Operator
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../gallery/how-to-guides/add-new-operator-compute-definition.html">
     Define Operator Computation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../gallery/how-to-guides/add-new-operator-rule-based.html">
     Using Rule-based Scheduling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../gallery/how-to-guides/add-new-operator-template-based.html">
     Using Template-based Scheduling
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../gallery/how-to-guides/add-operator-resolve-rule.html">
   Add Operator Resolve Rule
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../gallery/how-to-guides/add-subgraph-rewrite-rule.html">
   Add Sub-Graph Rewrite Rule
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../gallery/how-to-guides/visualize-flow-graph.html">
   Visualize Flow Graph
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Developer Guide
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../developer-guides/contributing.html">
   Contributing
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../developer-guides/hidet-script/index.html">
   Hidet Script
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../gallery/developer-guides/hidet-script-dynamic-kernel.html">
     Writing Dynamic kernel
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Notes
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../notes/operator-cache.html">
   Operator Cache
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Reference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../python_api/index.html">
   Python API
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../python_api/root.html">
     hidet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../python_api/option.html">
     hidet.option
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../python_api/driver.html">
     hidet.driver
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../python_api/cuda.html">
     hidet.cuda
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../python_api/tensor.html">
     hidet.Tensor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../python_api/data_types.html">
     hidet.dtypes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../python_api/ops/index.html">
     hidet.ops
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../../python_api/ir/index.html">
     hidet.ir
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../python_api/ir/type.html">
       hidet.ir.type
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../python_api/ir/expr.html">
       hidet.ir.expr
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../python_api/ir/stmt.html">
       hidet.ir.stmt
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../python_api/ir/func.html">
       hidet.ir.func
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../python_api/ir/compute.html">
       hidet.ir.compute
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../python_api/ir/task.html">
       hidet.ir.task
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../../python_api/graph/index.html">
     hidet.graph
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
    <label for="toctree-checkbox-6">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../../python_api/graph/frontend/index.html">
       hidet.graph.frontend
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
      <label for="toctree-checkbox-7">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../../python_api/graph/frontend/onnx.html">
         hidet.graph.frontend.onnx
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../../python_api/graph/frontend/torch.html">
         hidet.graph.frontend.torch
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../../python_api/graph/transforms/index.html">
       hidet.graph.transforms
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
      <label for="toctree-checkbox-8">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../../python_api/graph/transforms/subgraph_rewrite.html">
         Sub-graph Rewrite Pass
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../../python_api/graph/transforms/resolve_variant.html">
         Resolve Operator Pass
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../python_api/runtime/index.html">
     hidet.runtime
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../python_api/utils/index.html">
     hidet.utils
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../python_api/testing/index.html">
     hidet.testing
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../genindex.html">
   Index
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            <a href=/netron target=_blank>Customized Netron</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>
<a href="https://github.com/hidet-org/hidet"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="bottom"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1></h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <h1>Source code for hidet.graph.tensor</h1><div class="highlight"><pre>
<span></span><span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">,</span> <span class="n">Union</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">hidet.runtime.storage</span>
<span class="kn">import</span> <span class="nn">hidet.cuda</span>
<span class="kn">from</span> <span class="nn">hidet.ir</span> <span class="kn">import</span> <span class="n">dtypes</span>
<span class="kn">from</span> <span class="nn">hidet.ir.type</span> <span class="kn">import</span> <span class="n">DataType</span><span class="p">,</span> <span class="n">data_type</span>
<span class="kn">from</span> <span class="nn">hidet.ir.layout</span> <span class="kn">import</span> <span class="n">DataLayout</span><span class="p">,</span> <span class="n">RowMajorLayout</span>
<span class="kn">from</span> <span class="nn">hidet.runtime.storage</span> <span class="kn">import</span> <span class="n">Storage</span>
<span class="kn">from</span> <span class="nn">hidet.utils</span> <span class="kn">import</span> <span class="n">prod</span>
<span class="kn">from</span> <span class="nn">hidet.utils.overrides</span> <span class="kn">import</span> <span class="n">set_module</span>
<span class="kn">from</span> <span class="nn">hidet.runtime.device</span> <span class="kn">import</span> <span class="n">Device</span><span class="p">,</span> <span class="n">instantiate_device</span>


<span class="nd">@set_module</span><span class="p">(</span><span class="s1">&#39;hidet&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;An n-dimension array, could be symbolic or concrete.</span>

<span class="sd">    This class defines an n-dimension array.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    shape: Sequence[int]</span>
<span class="sd">        The shape of the tensor.</span>

<span class="sd">    dtype: DataType or str</span>
<span class="sd">        The data type of the tensor.</span>

<span class="sd">    device: Device or str</span>
<span class="sd">        The device of the tensor.</span>

<span class="sd">    storage: Storage, optional</span>
<span class="sd">        The storage of the tensor. None indicates it is a symbolic tensor.</span>

<span class="sd">    layout: DataLayout, optional</span>
<span class="sd">        The data layout of the tensor.</span>

<span class="sd">    trace: Tuple[Operator, int], optional</span>
<span class="sd">        Where this tensor is derived from. A trace = (op, i) indicates that this tensor is the i-th output of the op</span>
<span class="sd">        operator.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">storage</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">trace</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">hidet.graph.operator</span> <span class="kn">import</span> <span class="n">Operator</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">shape</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">:</span> <span class="n">DataType</span> <span class="o">=</span> <span class="n">data_type</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">:</span> <span class="n">Device</span> <span class="o">=</span> <span class="n">instantiate_device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_storage</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Storage</span><span class="p">]</span> <span class="o">=</span> <span class="n">storage</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_layout</span><span class="p">:</span> <span class="n">DataLayout</span> <span class="o">=</span> <span class="n">layout</span> <span class="k">if</span> <span class="n">layout</span> <span class="k">else</span> <span class="n">DataLayout</span><span class="o">.</span><span class="n">row_major</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_trace</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Operator</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="n">trace</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">shape</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The shape of the tensor.</span>

<span class="sd">        The shape is a tuple of integers indicating the size of the tensor along each dimension.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        shape: Tuple[int, ...]</span>
<span class="sd">            The shape of the tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">dtype</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataType</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The data type of the tensor.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dtype: DataType</span>
<span class="sd">            The data type of the tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Device</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The device of the tensor.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        device: Device</span>
<span class="sd">            The device of the tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">storage</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Storage</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The storage of the tensor.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        storage: Storage</span>
<span class="sd">            The storage of the tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_storage</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">trace</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The producer and the index of outputs of the producer of this tensor.</span>

<span class="sd">        This attribute is used to track how this tensor is computed. None indicates this is a leaf tensor where the</span>
<span class="sd">        value will be given by the user. Otherwise, it will be a tuple with (operator, index) where operator is the</span>
<span class="sd">        producer of this tensor and index is the index of the output of the operator.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        trace: Tuple[Operator, int]</span>
<span class="sd">            The trace of this tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trace</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The number of elements in the tensor.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        size: int</span>
<span class="sd">            The number of elements in the tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">prod</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">layout</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataLayout</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The data layout of the tensor.</span>

<span class="sd">        .. note::</span>

<span class="sd">          This attribute is experimental and might change in the future.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        layout: DataLayout</span>
<span class="sd">            The data layout of the tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_layout</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">nbytes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The number of bytes of the tensor.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ret: int</span>
<span class="sd">            The number of bytes.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">prod</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">nbytes</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">op</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The operator that produces this tensor.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ret: hidet.graph.operator.Operator, optional</span>
<span class="sd">            The operator that produces this tensor. None indicates it is not traced.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">trace</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trace</span> <span class="k">else</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="fm">__pos__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="fm">__neg__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">.ops</span> <span class="kn">import</span> <span class="n">negative</span>

        <span class="k">return</span> <span class="n">negative</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__add__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">.ops</span> <span class="kn">import</span> <span class="n">add</span>

        <span class="k">return</span> <span class="n">add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__sub__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">.ops</span> <span class="kn">import</span> <span class="n">subtract</span>

        <span class="k">return</span> <span class="n">subtract</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__mul__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">.ops</span> <span class="kn">import</span> <span class="n">multiply</span><span class="p">,</span> <span class="n">utils</span>

        <span class="k">return</span> <span class="n">multiply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__truediv__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">.ops</span> <span class="kn">import</span> <span class="n">divide</span><span class="p">,</span> <span class="n">utils</span>

        <span class="k">return</span> <span class="n">divide</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__mod__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">.ops</span> <span class="kn">import</span> <span class="n">mod</span><span class="p">,</span> <span class="n">utils</span>

        <span class="k">return</span> <span class="n">mod</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__pow__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">power</span><span class="p">,</span> <span class="n">modulo</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">.ops</span> <span class="kn">import</span> <span class="nb">pow</span><span class="p">,</span> <span class="n">utils</span>

        <span class="k">return</span> <span class="nb">pow</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">power</span><span class="p">,</span> <span class="bp">self</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__matmul__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">.ops</span> <span class="kn">import</span> <span class="n">matmul</span><span class="p">,</span> <span class="n">utils</span>

        <span class="k">return</span> <span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__invert__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">.ops</span> <span class="kn">import</span> <span class="n">bitwise_invert</span>

        <span class="k">return</span> <span class="n">bitwise_invert</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__and__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">.ops</span> <span class="kn">import</span> <span class="n">bitwise_and</span><span class="p">,</span> <span class="n">utils</span>

        <span class="k">return</span> <span class="n">bitwise_and</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__or__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">.ops</span> <span class="kn">import</span> <span class="n">bitwise_or</span><span class="p">,</span> <span class="n">utils</span>

        <span class="k">return</span> <span class="n">bitwise_or</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__xor__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">.ops</span> <span class="kn">import</span> <span class="n">bitwise_xor</span><span class="p">,</span> <span class="n">utils</span>

        <span class="k">return</span> <span class="n">bitwise_xor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__lshift__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">.ops</span> <span class="kn">import</span> <span class="n">bitwise_left_shift</span><span class="p">,</span> <span class="n">utils</span>

        <span class="k">return</span> <span class="n">bitwise_left_shift</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__rshift__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">.ops</span> <span class="kn">import</span> <span class="n">bitwise_right_shift</span><span class="p">,</span> <span class="n">utils</span>

        <span class="k">return</span> <span class="n">bitwise_right_shift</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__lt__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">.ops</span> <span class="kn">import</span> <span class="n">less</span><span class="p">,</span> <span class="n">utils</span>

        <span class="k">return</span> <span class="n">less</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__le__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">.ops</span> <span class="kn">import</span> <span class="n">less_equal</span><span class="p">,</span> <span class="n">utils</span>

        <span class="k">return</span> <span class="n">less_equal</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__gt__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">.ops</span> <span class="kn">import</span> <span class="n">greater</span><span class="p">,</span> <span class="n">utils</span>

        <span class="k">return</span> <span class="n">greater</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__eq__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">.ops</span> <span class="kn">import</span> <span class="n">equal</span><span class="p">,</span> <span class="n">utils</span>

        <span class="k">return</span> <span class="n">equal</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__ne__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">.ops</span> <span class="kn">import</span> <span class="n">not_equal</span><span class="p">,</span> <span class="n">utils</span>

        <span class="k">return</span> <span class="n">not_equal</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__radd__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">.ops</span> <span class="kn">import</span> <span class="n">add</span>

        <span class="k">return</span> <span class="n">add</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__rsub__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">.ops</span> <span class="kn">import</span> <span class="n">subtract</span>

        <span class="k">return</span> <span class="n">subtract</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__rmul__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">.ops</span> <span class="kn">import</span> <span class="n">multiply</span>

        <span class="k">return</span> <span class="n">multiply</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__abs__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">.ops</span> <span class="kn">import</span> <span class="nb">abs</span>

        <span class="k">return</span> <span class="nb">abs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__bool__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;Boolean value of Tensor with more than one value is ambiguous&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">bool</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

    <span class="k">def</span> <span class="fm">__float__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;only one element tensors can be converted to Python scalars&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

    <span class="k">def</span> <span class="fm">__index__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;only one element tensors can be converted to Python scalars&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

    <span class="k">def</span> <span class="fm">__int__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;only one element tensors can be converted to Python scalars&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">head</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">signature</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="p">:</span>
            <span class="n">array_str</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
            <span class="k">return</span> <span class="s1">&#39;</span><span class="si">{}</span><span class="se">\n</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">head</span><span class="p">,</span> <span class="n">array_str</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trace</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">head</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="s1">&#39;</span><span class="si">{}</span><span class="se">\n</span><span class="s1">from </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">head</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trace</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">hidet.graph.ops</span> <span class="kn">import</span> <span class="n">strided_slice</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">item</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">item</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="n">item</span><span class="p">])</span>

        <span class="c1"># now, the item could have</span>
        <span class="c1"># 1. integer index</span>
        <span class="c1"># 2. slice</span>
        <span class="c1"># 3. Ellipsis</span>
        <span class="c1"># 4. None</span>
        <span class="c1"># e.g., [1, 3:5, ..., None]</span>

        <span class="c1"># process Ellipsis</span>
        <span class="c1"># e.g., x[1, ..., 2] -&gt; x[1, :, :, 2]</span>
        <span class="k">if</span> <span class="bp">Ellipsis</span> <span class="ow">in</span> <span class="n">item</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">item</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="bp">Ellipsis</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Only one ellipsis allowed in index.&#39;</span><span class="p">)</span>
            <span class="n">ellipsis_index</span> <span class="o">=</span> <span class="n">item</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="bp">Ellipsis</span><span class="p">)</span>
            <span class="n">ellipsis_ndim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span> <span class="nb">sum</span><span class="p">([</span><span class="mi">1</span> <span class="k">if</span> <span class="n">axis</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="bp">Ellipsis</span><span class="p">]</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">item</span><span class="p">])</span>
            <span class="n">ellipsis_ndim</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">ellipsis_ndim</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="n">item</span> <span class="o">=</span> <span class="n">item</span><span class="p">[:</span><span class="n">ellipsis_index</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">),)</span> <span class="o">*</span> <span class="n">ellipsis_ndim</span> <span class="o">+</span> <span class="n">item</span><span class="p">[</span><span class="n">ellipsis_index</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">:]</span>

        <span class="c1"># process None</span>
        <span class="c1"># e.g., x[2, None, 3] -&gt; x[2, 1, 3]</span>
        <span class="k">if</span> <span class="kc">None</span> <span class="ow">in</span> <span class="n">item</span><span class="p">:</span>
            <span class="n">dims</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">item</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">v</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">dims</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="n">item</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span> <span class="k">if</span> <span class="n">v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">item</span><span class="p">]</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dims</span><span class="p">)[</span><span class="n">item</span><span class="p">]</span>

        <span class="k">assert</span> <span class="kc">None</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">item</span>

        <span class="c1"># normalize index</span>
        <span class="n">normalized_item</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">item</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">v</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">v</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">v</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">v</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
                    <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span>
                        <span class="s1">&#39;index </span><span class="si">{}</span><span class="s1"> is out of bound for dimension </span><span class="si">{}</span><span class="s1"> with size </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                    <span class="p">)</span>
                <span class="n">normalized_item</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">normalized_item</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
        <span class="n">item</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">normalized_item</span><span class="p">)</span>

        <span class="c1"># process slice and integer index</span>
        <span class="n">rank</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">rank</span><span class="p">:</span>
            <span class="n">item</span> <span class="o">=</span> <span class="n">item</span> <span class="o">+</span> <span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">),)</span>
        <span class="n">starts</span><span class="p">,</span> <span class="n">ends</span><span class="p">,</span> <span class="n">steps</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="n">squeeze_dims</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">dim</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">item</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                <span class="n">squeeze_dims</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
                <span class="n">starts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
                <span class="n">ends</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">steps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">slice</span><span class="p">)</span>
                <span class="n">starts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">start</span><span class="p">)</span>
                <span class="n">ends</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">stop</span><span class="p">)</span>
                <span class="n">steps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">step</span><span class="p">)</span>
        <span class="n">sliced</span> <span class="o">=</span> <span class="n">strided_slice</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">starts</span><span class="p">,</span> <span class="n">ends</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="n">steps</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">squeeze_dims</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">sliced</span>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;hidet.Tensor does not support iteration.&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__hash__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        This is a hack to make hidet.Tensor hashable. There are some places where we need to use tensor as the key</span>
<span class="sd">        of a dictionary, (e.g., in a graph optimization pass or graph execution). However, to implement a correct</span>
<span class="sd">        protocol for hashable objects, we need to implement __eq__ as well to compare two objects when their hash</span>
<span class="sd">        values are equal. But as a tensor, the __eq__ method is used to do element-wise comparison, and it returns</span>
<span class="sd">        a tensor instead of a boolean value. Thus, there will be a problem when the dict that takes Tensor as key type</span>
<span class="sd">        has other kinds of objects (e.g., int). We deliberately ignore this problem here in exchange for the convenience</span>
<span class="sd">        of using tensor as the key of a dict.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">id</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;shape&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
            <span class="s1">&#39;dtype&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
            <span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="s1">&#39;data&#39;</span><span class="p">:</span> <span class="n">data</span><span class="p">,</span>
            <span class="s1">&#39;layout&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">layout</span><span class="p">,</span>
            <span class="s1">&#39;trace&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">trace</span><span class="p">,</span>
        <span class="p">}</span>

    <span class="k">def</span> <span class="nf">__setstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span>
            <span class="n">tensor</span> <span class="o">=</span> <span class="n">from_numpy</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">state</span><span class="p">[</span><span class="s1">&#39;device&#39;</span><span class="p">])</span>
            <span class="n">storage</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">storage</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">storage</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s1">&#39;device&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s1">&#39;shape&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s1">&#39;dtype&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_storage</span> <span class="o">=</span> <span class="n">storage</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_layout</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s1">&#39;layout&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_trace</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s1">&#39;trace&#39;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">__dlpack__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stream</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function is used to support interoperability with other frameworks that support __dlpack__ protocol.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">.impl.dlpack</span> <span class="kn">import</span> <span class="n">to_dlpack</span>

        <span class="k">if</span> <span class="n">stream</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">consumer_stream</span> <span class="o">=</span> <span class="n">hidet</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">ExternalStream</span><span class="p">(</span><span class="n">stream</span><span class="p">)</span>
            <span class="n">provider_stream</span> <span class="o">=</span> <span class="n">hidet</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">consumer_stream</span> <span class="o">!=</span> <span class="n">provider_stream</span><span class="p">:</span>
                <span class="n">event</span> <span class="o">=</span> <span class="n">hidet</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Event</span><span class="p">()</span>
                <span class="n">event</span><span class="o">.</span><span class="n">record</span><span class="p">(</span><span class="n">provider_stream</span><span class="p">)</span>
                <span class="n">consumer_stream</span><span class="o">.</span><span class="n">wait_event</span><span class="p">(</span><span class="n">event</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">to_dlpack</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__dlpack_device__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function is used to support interoperability with other frameworks that support __dlpack__ protocol.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">.impl.dlpack</span> <span class="kn">import</span> <span class="n">to_dlpack_device</span>

        <span class="k">return</span> <span class="n">to_dlpack_device</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

<div class="viewcode-block" id="Tensor.tolist"><a class="viewcode-back" href="../../../python_api/tensor.html#hidet.graph.Tensor.tolist">[docs]</a>    <span class="k">def</span> <span class="nf">tolist</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Convert the tensor to a nested list of numbers.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ret: the nested list of numbers</span>
<span class="sd">            The nested list of numbers. The number of nested levels is equal to the rank of the tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span></div>

<div class="viewcode-block" id="Tensor.to_device"><a class="viewcode-back" href="../../../python_api/tensor.html#hidet.graph.Tensor.to_device">[docs]</a>    <span class="k">def</span> <span class="nf">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="o">/</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Move the tensor to the specified device.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        device: Device or str</span>
<span class="sd">            The device to move the tensor to.</span>

<span class="sd">        stream: Stream or None</span>
<span class="sd">            The stream to use for the copy. If None, the current stream is used.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ret: Tensor</span>
<span class="sd">            The tensor on the specified device.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">instantiate_device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">device</span><span class="o">.</span><span class="n">is_cpu</span><span class="p">():</span>
            <span class="n">tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">device</span><span class="o">.</span><span class="n">is_cuda</span><span class="p">():</span>
            <span class="n">tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cuda_async</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="n">stream</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Cannot recognize device </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">tensor</span></div>

<div class="viewcode-block" id="Tensor.item"><a class="viewcode-back" href="../../../python_api/tensor.html#hidet.graph.Tensor.item">[docs]</a>    <span class="k">def</span> <span class="nf">item</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Convert the tensor to a scalar value.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">prod</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dims</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">))))</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ret</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Cannot convert tensor to scalar.&#39;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">ret</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;Only support .item() method for tensor with only one element&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="Tensor.signature"><a class="viewcode-back" href="../../../python_api/tensor.html#hidet.graph.Tensor.signature">[docs]</a>    <span class="k">def</span> <span class="nf">signature</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Get the signature of the tensor.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ret: str</span>
<span class="sd">            The signature of the tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="s2">&quot;Tensor(shape=</span><span class="si">{}</span><span class="s2">, dtype=&#39;</span><span class="si">{}</span><span class="s2">&#39;, device=&#39;</span><span class="si">{}</span><span class="s2">&#39;)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span></div>

<div class="viewcode-block" id="Tensor.is_symbolic"><a class="viewcode-back" href="../../../python_api/tensor.html#hidet.graph.Tensor.is_symbolic">[docs]</a>    <span class="k">def</span> <span class="nf">is_symbolic</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Check if the tensor is symbolic.</span>

<span class="sd">        A tensor is symbolic if it is not backed by any storage (i.e., ``self.storage is None``).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ret: bool</span>
<span class="sd">            True if the tensor is symbolic, False otherwise.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">storage</span> <span class="ow">is</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="Tensor.contiguous"><a class="viewcode-back" href="../../../python_api/tensor.html#hidet.graph.Tensor.contiguous">[docs]</a>    <span class="k">def</span> <span class="nf">contiguous</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create a tensor with contiguous row-major layout.</span>

<span class="sd">        If the tensor already has the continuous row-major layout, this tensor is returned directly.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ret: Tensor</span>
<span class="sd">            The tensor with contiguous row-major layout.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layout</span><span class="p">,</span> <span class="n">RowMajorLayout</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span></div>

<div class="viewcode-block" id="Tensor.reshape"><a class="viewcode-back" href="../../../python_api/tensor.html#hidet.graph.Tensor.reshape">[docs]</a>    <span class="k">def</span> <span class="nf">reshape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]):</span>
        <span class="sd">&quot;&quot;&quot;Create a reshaped tensor.</span>

<span class="sd">        See Also :func:`hidet.graph.ops.reshape`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        shape: Sequence[int]</span>
<span class="sd">            The new shape.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ret: Tensor</span>
<span class="sd">            The reshaped tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">.ops</span> <span class="kn">import</span> <span class="n">reshape</span>

        <span class="k">return</span> <span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span></div>

<div class="viewcode-block" id="Tensor.squeeze"><a class="viewcode-back" href="../../../python_api/tensor.html#hidet.graph.Tensor.squeeze">[docs]</a>    <span class="k">def</span> <span class="nf">squeeze</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dims</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]]):</span>
        <span class="sd">&quot;&quot;&quot;Create a squeezed tensor.</span>

<span class="sd">        See Also :func:`hidet.graph.ops.squeeze`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        dims: Union[int, Sequence[int]]</span>
<span class="sd">            The dimension(s) to squeeze.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ret: Tensor</span>
<span class="sd">            The squeezed tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">.ops</span> <span class="kn">import</span> <span class="n">squeeze</span>

        <span class="k">return</span> <span class="n">squeeze</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dims</span><span class="p">)</span></div>

<div class="viewcode-block" id="Tensor.unsqueeze"><a class="viewcode-back" href="../../../python_api/tensor.html#hidet.graph.Tensor.unsqueeze">[docs]</a>    <span class="k">def</span> <span class="nf">unsqueeze</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dims</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]]):</span>
        <span class="sd">&quot;&quot;&quot;Create a unsqueezed tensor.</span>

<span class="sd">        See Also :func:`hidet.graph.ops.unsqueeze`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        dims: Union[int, Sequence[int]]</span>
<span class="sd">            The dimensions to unsqueeze.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ret: Tensor</span>
<span class="sd">            The unsqueezed tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">.ops</span> <span class="kn">import</span> <span class="n">unsqueeze</span>

        <span class="k">return</span> <span class="n">unsqueeze</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dims</span><span class="p">)</span></div>

<div class="viewcode-block" id="Tensor.rearrange"><a class="viewcode-back" href="../../../python_api/tensor.html#hidet.graph.Tensor.rearrange">[docs]</a>    <span class="k">def</span> <span class="nf">rearrange</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">plan</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]):</span>
        <span class="sd">&quot;&quot;&quot;Create a rearranged tensor.</span>

<span class="sd">        See Also :func:`hidet.graph.ops.rearrange`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        plan: List[List[int]]</span>
<span class="sd">            The rearrange plan.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ret: Tensor</span>
<span class="sd">            The rearranged tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">.ops</span> <span class="kn">import</span> <span class="n">rearrange</span>

        <span class="k">return</span> <span class="n">rearrange</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">plan</span><span class="p">)</span></div>

<div class="viewcode-block" id="Tensor.sum"><a class="viewcode-back" href="../../../python_api/tensor.html#hidet.graph.Tensor.sum">[docs]</a>    <span class="k">def</span> <span class="nf">sum</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dims</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span> <span class="n">keep_dim</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create a sum reduced tensor.</span>

<span class="sd">        See Also :func:`hidet.graph.ops.reduce_sum`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        dims: Union[int, List[int]]</span>
<span class="sd">            The dimensions to sum up.</span>

<span class="sd">        keep_dim: bool</span>
<span class="sd">            Whether to keep the reduced dimensions.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ret: Tensor</span>
<span class="sd">            The reduced tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">.ops</span> <span class="kn">import</span> <span class="nb">sum</span>

        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="n">dims</span><span class="p">,</span> <span class="n">keep_dim</span><span class="o">=</span><span class="n">keep_dim</span><span class="p">)</span></div>

<div class="viewcode-block" id="Tensor.mean"><a class="viewcode-back" href="../../../python_api/tensor.html#hidet.graph.Tensor.mean">[docs]</a>    <span class="k">def</span> <span class="nf">mean</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dims</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span> <span class="n">keep_dim</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create a mean reduced tensor.</span>

<span class="sd">        See Also :func:`hidet.graph.ops.reduce_mean`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        dims: Union[int, List[int]]</span>
<span class="sd">            The dimensions to average up.</span>

<span class="sd">        keep_dim: bool</span>
<span class="sd">            Whether to keep the reduced dimensions.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ret: Tensor</span>
<span class="sd">            The reduced tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">.ops</span> <span class="kn">import</span> <span class="n">mean</span>

        <span class="k">return</span> <span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="n">dims</span><span class="p">,</span> <span class="n">keep_dim</span><span class="o">=</span><span class="n">keep_dim</span><span class="p">)</span></div>

<div class="viewcode-block" id="Tensor.astype"><a class="viewcode-back" href="../../../python_api/tensor.html#hidet.graph.Tensor.astype">[docs]</a>    <span class="k">def</span> <span class="nf">astype</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Cast the data type of current tensor.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        dtype: DataType or str</span>
<span class="sd">            The target data type to convert to.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ret: Tensor</span>
<span class="sd">            The tensor with the new data type.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">.ops</span> <span class="kn">import</span> <span class="n">cast</span>

        <span class="k">return</span> <span class="n">cast</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span></div>

<div class="viewcode-block" id="Tensor.to"><a class="viewcode-back" href="../../../python_api/tensor.html#hidet.graph.Tensor.to">[docs]</a>    <span class="k">def</span> <span class="nf">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Cast the data type of current tensor or/and move it to another device.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        dtype: DataType or str, optional</span>
<span class="sd">            The target data type to convert to. None indicates unchanged.</span>

<span class="sd">        device: Device or str, optional</span>
<span class="sd">            The target device to copy the tensor. None indicates unchanged.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ret: Tensor</span>
<span class="sd">            The tensor with the new data type on target device.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">.ops</span> <span class="kn">import</span> <span class="n">cast</span>

        <span class="n">tensor</span> <span class="o">=</span> <span class="bp">self</span>
        <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">tensor</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">device</span> <span class="o">=</span> <span class="n">instantiate_device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">device</span><span class="o">.</span><span class="n">is_cpu</span><span class="p">():</span>
                <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
            <span class="k">elif</span> <span class="n">device</span><span class="o">.</span><span class="n">is_cuda</span><span class="p">():</span>
                <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Cannot recognize device </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">tensor</span></div>

<div class="viewcode-block" id="Tensor.cpu"><a class="viewcode-back" href="../../../python_api/tensor.html#hidet.graph.Tensor.cpu">[docs]</a>    <span class="k">def</span> <span class="nf">cpu</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create a copy of self tensor on cpu device.</span>

<span class="sd">        If the current tensor is already on cpu device, self is returned.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ret: Tensor</span>
<span class="sd">            The new tensor or self.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cpu&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trace</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="s1">&#39;cpu&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">storage</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">layout</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Please use .detach() to detach a trace variable first.&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="Tensor.cuda"><a class="viewcode-back" href="../../../python_api/tensor.html#hidet.graph.Tensor.cuda">[docs]</a>    <span class="k">def</span> <span class="nf">cuda</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create a copy of self tensor on cuda device.</span>

<span class="sd">        If the current tensor is already on cuda device, self is returned.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        device: Device, optional</span>
<span class="sd">            The target cuda device. None indicates the current cuda device.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ret: Tensor</span>
<span class="sd">            The new tensor or self.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">instantiate_device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="n">device</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trace</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="n">device</span><span class="o">.</span><span class="n">id</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">storage</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">layout</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Please use .detach() to detach a trace variable first.&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="Tensor.copy"><a class="viewcode-back" href="../../../python_api/tensor.html#hidet.graph.Tensor.copy">[docs]</a>    <span class="k">def</span> <span class="nf">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Create a copy of current tensor.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ret: Tensor</span>
<span class="sd">            A new tensor with the same contents as the current one.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trace</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Please use .detach() to detach a trace variable first before copying.&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span>
            <span class="n">shape</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="n">storage</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span>
            <span class="n">layout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">layout</span><span class="p">,</span>
            <span class="n">trace</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Tensor.copy_async"><a class="viewcode-back" href="../../../python_api/tensor.html#hidet.graph.Tensor.copy_async">[docs]</a>    <span class="k">def</span> <span class="nf">copy_async</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Create a copy of current tensor asynchronously.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        stream: hidet.cuda.Stream, optional</span>
<span class="sd">            The stream to copy the tensor. None indicates the current stream of the device where self tensor is on.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ret: Tensor</span>
<span class="sd">            A new tensor with the same contents as the current one.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trace</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Please use .detach() to detach a trace variable first before copying.&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span>
            <span class="n">shape</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="n">storage</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">copy_async</span><span class="p">(</span><span class="n">stream</span><span class="p">),</span>
            <span class="n">layout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">layout</span><span class="p">,</span>
            <span class="n">trace</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Tensor.detach"><a class="viewcode-back" href="../../../python_api/tensor.html#hidet.graph.Tensor.detach">[docs]</a>    <span class="k">def</span> <span class="nf">detach</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Detach the current tensor from tracing.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ret: Tensor</span>
<span class="sd">            The detached tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trace</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span>
                <span class="n">shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                <span class="n">storage</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="p">,</span>
                <span class="n">layout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">layout</span><span class="p">,</span>
                <span class="n">trace</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="p">)</span></div>

<div class="viewcode-block" id="Tensor.cpu_async"><a class="viewcode-back" href="../../../python_api/tensor.html#hidet.graph.Tensor.cpu_async">[docs]</a>    <span class="k">def</span> <span class="nf">cpu_async</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Copy the tensor to CPU asynchronously.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        stream: hidet.cuda.Stream, optional</span>
<span class="sd">            The stream to copy the tensor to CPU on.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ret: Tensor</span>
<span class="sd">            The tensor on CPU.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cpu&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trace</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">ret</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="s1">&#39;cpu&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">cpu_async</span><span class="p">(</span><span class="n">stream</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">storage</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">layout</span>
                <span class="p">)</span>
                <span class="k">return</span> <span class="n">ret</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Please use .detach() to detach a trace variable first.&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="Tensor.cuda_async"><a class="viewcode-back" href="../../../python_api/tensor.html#hidet.graph.Tensor.cuda_async">[docs]</a>    <span class="k">def</span> <span class="nf">cuda_async</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Copy the tensor to GPU asynchronously.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        device: Device, optional</span>
<span class="sd">            The target cuda device. None indicates the current cuda device.</span>

<span class="sd">        stream: hidet.cuda.Stream, optional</span>
<span class="sd">            The stream to copy the tensor to GPU on. None indicates the current stream.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ret: Tensor</span>
<span class="sd">            The tensor on GPU.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">instantiate_device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">is_cuda</span><span class="p">():</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trace</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">ret</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                    <span class="n">device</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">cuda_async</span><span class="p">(</span><span class="n">device</span><span class="o">.</span><span class="n">id</span><span class="p">,</span> <span class="n">stream</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">storage</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">layout</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">return</span> <span class="n">ret</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Please use .detach() to detach a trace variable first.&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="Tensor.numpy"><a class="viewcode-back" href="../../../python_api/tensor.html#hidet.graph.Tensor.numpy">[docs]</a>    <span class="k">def</span> <span class="nf">numpy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Convert the tensor to a numpy array.</span>

<span class="sd">        The tensor must be on CPU device. Otherwise, a RuntimeError will be raised. The returned numpy array will share</span>
<span class="sd">        the same memory with the tensor.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ret: np.ndarray</span>
<span class="sd">            The numpy array.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">!=</span> <span class="s1">&#39;cpu&#39;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;Cannot convert a tensor on </span><span class="si">{}</span><span class="s1"> to numpy array.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">in</span> <span class="p">[</span><span class="n">dtypes</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">tfloat32</span><span class="p">]:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;numpy does not support </span><span class="si">{}</span><span class="s1">, converting to float32&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">name</span><span class="p">))</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">boolean</span><span class="p">:</span>
            <span class="c1"># workaround for numpy not supporting exporting boolean to dlpack</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">from_dlpack</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;uint8&#39;</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">bool_</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">from_dlpack</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></div>

<div class="viewcode-block" id="Tensor.torch"><a class="viewcode-back" href="../../../python_api/tensor.html#hidet.graph.Tensor.torch">[docs]</a>    <span class="k">def</span> <span class="nf">torch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Convert to a torch tensor.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ret: torch.Tensor</span>
<span class="sd">            The torch tensor that shares the memory with the hidet tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span> <span class="nn">torch</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_dlpack</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></div>


<div class="viewcode-block" id="empty"><a class="viewcode-back" href="../../../python_api/root.html#hidet.graph.empty">[docs]</a><span class="k">def</span> <span class="nf">empty</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create an uninitialized tensor.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    shape: Sequence[int]</span>
<span class="sd">        The shape of new tensor.</span>

<span class="sd">    dtype: str or DataType</span>
<span class="sd">        The data type of element of the tensor.</span>

<span class="sd">    device: Device or str, default &#39;cpu&#39;</span>
<span class="sd">        The device of the new tensor is created on.</span>

<span class="sd">    layout: DataLayout, optional</span>
<span class="sd">        The layout of the new tensor. None indicates the default layout (row-major layout).</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ret: Tensor</span>
<span class="sd">        The created tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">data_type</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">num_bytes</span> <span class="o">=</span> <span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">dtype</span><span class="o">.</span><span class="n">nbytes</span>
    <span class="n">storage</span> <span class="o">=</span> <span class="n">Storage</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">num_bytes</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">storage</span><span class="o">=</span><span class="n">storage</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">layout</span><span class="p">)</span></div>


<div class="viewcode-block" id="symbol"><a class="viewcode-back" href="../../../python_api/root.html#hidet.graph.symbol">[docs]</a><span class="k">def</span> <span class="nf">symbol</span><span class="p">(</span><span class="n">shape</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a symbolic tensor.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    shape: Sequence[int]</span>
<span class="sd">        The shape of new tensor.</span>

<span class="sd">    dtype: str</span>
<span class="sd">        The data type of element of the tensor.</span>

<span class="sd">    device: Device or str, default &#39;cpu&#39;</span>
<span class="sd">        The device of the new tensor is created on.</span>

<span class="sd">    layout: DataLayout, optional</span>
<span class="sd">        The layout of the new tensor. None indicates the default layout (row-major layout).</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ret: Tensor</span>
<span class="sd">        The created tensor.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">storage</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">layout</span><span class="p">)</span></div>


<div class="viewcode-block" id="zeros"><a class="viewcode-back" href="../../../python_api/root.html#hidet.graph.zeros">[docs]</a><span class="k">def</span> <span class="nf">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a tensor initialized with zero.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    shape: Sequence[int]</span>
<span class="sd">        The shape of new tensor.</span>

<span class="sd">    dtype: str</span>
<span class="sd">        The data type of element of the tensor.</span>

<span class="sd">    device: Device or str, default &#39;cpu&#39;</span>
<span class="sd">        The device of the new tensor is created on.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ret: Tensor</span>
<span class="sd">        The created tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">data_type</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">full</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">.</span><span class="n">zero</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span></div>


<div class="viewcode-block" id="ones"><a class="viewcode-back" href="../../../python_api/root.html#hidet.graph.ones">[docs]</a><span class="k">def</span> <span class="nf">ones</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a tensor initialized with one.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    shape: Sequence[int]</span>
<span class="sd">        The shape of new tensor.</span>

<span class="sd">    dtype: DataType or str, default &#39;float32&#39;</span>
<span class="sd">        The data type of element of the tensor.</span>

<span class="sd">    device: Device or str, default &#39;cpu&#39;</span>
<span class="sd">        The device of the new tensor is created on.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ret: Tensor</span>
<span class="sd">        The created tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">data_type</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">full</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">.</span><span class="n">one</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span></div>


<div class="viewcode-block" id="full"><a class="viewcode-back" href="../../../python_api/root.html#hidet.graph.full">[docs]</a><span class="k">def</span> <span class="nf">full</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">fill_value</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a tensor initialized with given constant.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    shape: Sequence[int]</span>
<span class="sd">        The shape of new tensor.</span>

<span class="sd">    fill_value: float or int or hidet.ir.Constant</span>
<span class="sd">        The constant to initialize the new tensor.</span>

<span class="sd">    dtype: DataType or str, default &#39;float32&#39;</span>
<span class="sd">        The data type of element of the tensor.</span>

<span class="sd">    device: Device or str, default &#39;cpu&#39;</span>
<span class="sd">        The device of the new tensor is created on.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ret: Tensor</span>
<span class="sd">        The created tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">hidet</span> <span class="kn">import</span> <span class="n">ops</span>

    <span class="n">dtype</span> <span class="o">=</span> <span class="n">data_type</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ops</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">fill_value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span></div>


<div class="viewcode-block" id="randn"><a class="viewcode-back" href="../../../python_api/root.html#hidet.graph.randn">[docs]</a><span class="k">def</span> <span class="nf">randn</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a tensor with uniformly distributed values.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    shape: Sequence[int]</span>
<span class="sd">        The shape of new tensor.</span>

<span class="sd">    dtype: DataType or str, default &#39;float32&#39;</span>
<span class="sd">        The data type of element of the tensor.</span>

<span class="sd">    mean: float, default 0.0</span>
<span class="sd">        The mean of the uniform distribution.</span>

<span class="sd">    stddev: float, default 1.0</span>
<span class="sd">        The standard deviation of the uniform distribution.</span>

<span class="sd">    device: Device or str, default &#39;cpu&#39;</span>
<span class="sd">        The device of the new tensor is created on.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ret: Tensor</span>
<span class="sd">        The created tensor.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; randn([2, 3])</span>
<span class="sd">    Tensor(shape=[2, 3], dtype=&#39;float32&#39;, device=&#39;cuda&#39;)</span>
<span class="sd">    [[ 0.10720467 -1.6906018   0.06347568]</span>
<span class="sd">     [-0.37061226  0.562728    1.857547  ]]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">np_tensor</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">np_tensor</span> <span class="o">=</span> <span class="n">np_tensor</span> <span class="o">*</span> <span class="n">stddev</span> <span class="o">+</span> <span class="n">mean</span>
    <span class="n">hidet_tensor</span> <span class="o">=</span> <span class="n">from_numpy</span><span class="p">(</span><span class="n">np_tensor</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">hidet_tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">randint</span><span class="p">(</span><span class="n">low</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">shape</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(),</span> <span class="n">dtype</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;int32&#39;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="n">dtype_map</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;int32&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="s1">&#39;int64&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">}</span>
    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">dtype_map</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">high</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;int32&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">asarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">high</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype_map</span><span class="p">[</span><span class="n">dtype</span><span class="p">]))</span>


<div class="viewcode-block" id="empty_like"><a class="viewcode-back" href="../../../python_api/root.html#hidet.graph.empty_like">[docs]</a><span class="k">def</span> <span class="nf">empty_like</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create an uninitialized tensor with the same shape, dtype, and device as the given tensor.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data: Tensor</span>
<span class="sd">        The tensor to copy shape, dtype, and device from.</span>

<span class="sd">    shape: Sequence[int], optional</span>
<span class="sd">        The shape of new tensor. If None, the shape of data is used.</span>

<span class="sd">    dtype: DataType or str, optional</span>
<span class="sd">        The data type of element of the tensor. If None, the dtype of data is used.</span>

<span class="sd">    device: Device or str, optional</span>
<span class="sd">        The device of the new tensor is created on. If None, the device of data is used.</span>

<span class="sd">    layout: DataLayout, optional</span>
<span class="sd">        The layout of the new tensor. If None, the layout of data is used.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ret: Tensor</span>
<span class="sd">        The created tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">empty</span><span class="p">(</span>
        <span class="n">shape</span><span class="o">=</span><span class="n">shape</span> <span class="k">if</span> <span class="n">shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span> <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">data</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">device</span> <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">data</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="n">layout</span><span class="o">=</span><span class="n">layout</span> <span class="k">if</span> <span class="n">layout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">data</span><span class="o">.</span><span class="n">layout</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="symbol_like"><a class="viewcode-back" href="../../../python_api/root.html#hidet.graph.symbol_like">[docs]</a><span class="k">def</span> <span class="nf">symbol_like</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create a symbol tensor like an existing tensor.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data: Tensor</span>
<span class="sd">        The tensor to copy shape, dtype, and device from.</span>

<span class="sd">    shape: Sequence[int], optional</span>
<span class="sd">        The shape of new tensor. If None, the shape of data is used.</span>

<span class="sd">    dtype: DataType or str, optional</span>
<span class="sd">        The data type of element of the tensor. If None, the dtype of data is used.</span>

<span class="sd">    device: Device or str, optional</span>
<span class="sd">        The device of the new tensor is created on. If None, the device of data is used.</span>

<span class="sd">    layout: DataLayout, optional</span>
<span class="sd">        The layout of the new tensor. If None, the layout of data is used.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ret: Tensor</span>
<span class="sd">        The created symbol tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">symbol</span><span class="p">(</span>
        <span class="n">shape</span><span class="o">=</span><span class="n">shape</span> <span class="k">if</span> <span class="n">shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span> <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">data</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">device</span> <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">data</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="n">layout</span><span class="o">=</span><span class="n">layout</span> <span class="k">if</span> <span class="n">layout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">data</span><span class="o">.</span><span class="n">layout</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="zeros_like"><a class="viewcode-back" href="../../../python_api/root.html#hidet.graph.zeros_like">[docs]</a><span class="k">def</span> <span class="nf">zeros_like</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a tensor initialized with zero with the same shape, dtype, and device as the given tensor.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data: Tensor</span>
<span class="sd">        The tensor to copy shape, dtype, and device from.</span>

<span class="sd">    shape: Sequence[int], optional</span>
<span class="sd">        The shape of new tensor. If None, the shape of data is used.</span>

<span class="sd">    dtype: DataType or str, optional</span>
<span class="sd">        The data type of element of the tensor. If None, the dtype of data is used.</span>

<span class="sd">    device: Device or str, optional</span>
<span class="sd">        The device of the new tensor is created on. If None, the device of data is used.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ret: Tensor</span>
<span class="sd">        The created tensor with all elements as zero.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">zeros</span><span class="p">(</span>
        <span class="n">shape</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span> <span class="k">if</span> <span class="n">shape</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">shape</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span> <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">dtype</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">device</span> <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">device</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="ones_like"><a class="viewcode-back" href="../../../python_api/root.html#hidet.graph.ones_like">[docs]</a><span class="k">def</span> <span class="nf">ones_like</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a tensor initialized with one with the same shape, dtype, and device as the given tensor.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data: Tensor</span>
<span class="sd">        The tensor to copy shape, dtype, and device from.</span>

<span class="sd">    shape: Sequence[int], optional</span>
<span class="sd">        The shape of new tensor. If None, the shape of data is used.</span>

<span class="sd">    dtype: DataType or str, optional</span>
<span class="sd">        The data type of element of the tensor. If None, the dtype of data is used.</span>

<span class="sd">    device: Device or str, optional</span>
<span class="sd">        The device of the new tensor is created on. If None, the device of data is used.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ret: Tensor</span>
<span class="sd">        The created tensor with all elements as one.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">ones</span><span class="p">(</span>
        <span class="n">shape</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span> <span class="k">if</span> <span class="n">shape</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">shape</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span> <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">dtype</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">device</span> <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">device</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="full_like"><a class="viewcode-back" href="../../../python_api/root.html#hidet.graph.full_like">[docs]</a><span class="k">def</span> <span class="nf">full_like</span><span class="p">(</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">fill_value</span><span class="p">,</span>
    <span class="n">shape</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a tensor initialized with fill_value with the same shape, dtype, and device as the given tensor.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data: Tensor</span>
<span class="sd">        The tensor to copy shape, dtype, and device from.</span>

<span class="sd">    fill_value: int, float, or bool</span>
<span class="sd">        The value to fill the tensor with.</span>

<span class="sd">    shape: Sequence[int], optional</span>
<span class="sd">        The shape of new tensor. If None, the shape of data is used.</span>

<span class="sd">    dtype: DataType or str, optional</span>
<span class="sd">        The data type of element of the tensor. If None, the dtype of data is used.</span>

<span class="sd">    device: Device or str, optional</span>
<span class="sd">        The device of the new tensor is created on. If None, the device of data is used.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ret: Tensor</span>
<span class="sd">        The created tensor with all elements as fill_value.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">full</span><span class="p">(</span>
        <span class="n">shape</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span> <span class="k">if</span> <span class="n">shape</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">shape</span><span class="p">,</span>
        <span class="n">fill_value</span><span class="o">=</span><span class="n">fill_value</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span> <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">dtype</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">device</span> <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">device</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="randn_like"><a class="viewcode-back" href="../../../python_api/root.html#hidet.graph.randn_like">[docs]</a><span class="k">def</span> <span class="nf">randn_like</span><span class="p">(</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">shape</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a randomly initialized tensor with the same shape, dtype, and device as the given tensor.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data: Tensor</span>
<span class="sd">        The tensor to copy shape, dtype, and device from.</span>

<span class="sd">    shape: Sequence[int], optional</span>
<span class="sd">        The shape of new tensor. If None, the shape of data is used.</span>

<span class="sd">    dtype: DataType or str, optional</span>
<span class="sd">        The data type of element of the tensor. If None, the dtype of data is used.</span>

<span class="sd">    device: Device or str, optional</span>
<span class="sd">        The device of the new tensor is created on. If None, the device of data is used.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ret: Tensor</span>
<span class="sd">        The created tensor with random values sampled from a normal distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">randn</span><span class="p">(</span>
        <span class="n">shape</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span> <span class="k">if</span> <span class="n">shape</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">shape</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span> <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">dtype</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">device</span> <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">device</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="from_numpy"><a class="viewcode-back" href="../../../python_api/graph/index.html#hidet.graph.from_numpy">[docs]</a><span class="k">def</span> <span class="nf">from_numpy</span><span class="p">(</span><span class="n">nparray</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a tensor from a numpy array, sharing the memory with the numpy array when possible.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    nparray: numpy.ndarray</span>
<span class="sd">        The numpy array to create the tensor from.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ret: Tensor</span>
<span class="sd">        The created tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">nparray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;nparray must be a numpy array&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">nparray</span><span class="o">.</span><span class="n">flags</span><span class="p">[</span><span class="s1">&#39;WRITEABLE&#39;</span><span class="p">]:</span>
        <span class="c1"># make a copy if the array is read-only</span>
        <span class="n">nparray</span> <span class="o">=</span> <span class="n">nparray</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">nparray</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">bool_</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">from_dlpack</span><span class="p">(</span><span class="n">nparray</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;bool&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">from_dlpack</span><span class="p">(</span><span class="n">nparray</span><span class="p">)</span></div>


<div class="viewcode-block" id="from_dlpack"><a class="viewcode-back" href="../../../python_api/root.html#hidet.graph.from_dlpack">[docs]</a><span class="k">def</span> <span class="nf">from_dlpack</span><span class="p">(</span><span class="n">dltensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a hidet tensor from an object that implements the __dlpack__ protocol.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    dltensor: an object that implements the DLPack protocol.</span>
<span class="sd">        The object must have the method `__dlpack__` that returns a PyCapsule object with name `dltensor`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ret: Tensor</span>
<span class="sd">        The hidet tensor that shares the same storage with the DLPack tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.impl.dlpack</span> <span class="kn">import</span> <span class="n">from_dlpack_capsule</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">dltensor</span><span class="p">,</span> <span class="s1">&#39;__dlpack__&#39;</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;Expect a dltensor that implements __dlpack__ method.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">from_dlpack_capsule</span><span class="p">(</span><span class="n">dltensor</span><span class="o">.</span><span class="n">__dlpack__</span><span class="p">())</span></div>


<div class="viewcode-block" id="from_torch"><a class="viewcode-back" href="../../../python_api/root.html#hidet.graph.from_torch">[docs]</a><span class="k">def</span> <span class="nf">from_torch</span><span class="p">(</span><span class="n">torch_tensor</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create a hidet tensor from pytorch tensor.</span>

<span class="sd">    The created tensor shared the same memory as given pytorch tensor. Thus, any content</span>
<span class="sd">    modification on one tensor would be reflected on the other one.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    torch_tensor: torch.Tensor</span>
<span class="sd">        The pytorch tensor.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ret: Tensor</span>
<span class="sd">        The created hidet tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">torch</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">torch_tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Expect a torch.Tensor, got </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">torch_tensor</span><span class="p">)))</span>
    <span class="k">if</span> <span class="n">torch_tensor</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Please first call .detach() on the pytorch tensor before converting it to hidet.&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">torch_tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">torch_tensor</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">:</span>
        <span class="c1"># exporting torch.bool to dlpack is not supported by pytorch yet</span>
        <span class="k">return</span> <span class="n">from_dlpack</span><span class="p">(</span><span class="n">torch_tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;bool&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">from_dlpack</span><span class="p">(</span><span class="n">torch_tensor</span><span class="p">)</span></div>


<div class="viewcode-block" id="asarray"><a class="viewcode-back" href="../../../python_api/root.html#hidet.graph.asarray">[docs]</a><span class="k">def</span> <span class="nf">asarray</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="o">/</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert a list, tuple, or numpy ndarray to a hidet tensor.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    obj: Union[bool, int, float, List, Tuple, Tensor, np.ndarray]</span>
<span class="sd">        The object to be converted.</span>

<span class="sd">    dtype: DataType, optional</span>
<span class="sd">        The data type of the output tensor.</span>

<span class="sd">    device: Device or str</span>
<span class="sd">        The device of the output tensor.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ret: Tensor</span>
<span class="sd">        The hidet tensor converted from given object.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">hidet.ir.dtypes</span> <span class="kn">import</span> <span class="n">dtype_to_numpy</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="n">obj</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="n">from_numpy</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype_to_numpy</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span> <span class="k">if</span> <span class="n">dtype</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">array</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">:</span>
            <span class="c1"># numpy uses float64 as the default float data type, convert it to float32 as hidet takes float32 as default</span>
            <span class="n">array</span> <span class="o">=</span> <span class="n">array</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="n">from_numpy</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ret</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span></div>
</pre></div>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Hidet Team<br/>
  
      &copy; Copyright 2022, Hidet Authors.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>