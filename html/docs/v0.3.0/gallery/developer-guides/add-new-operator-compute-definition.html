

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-406WJTRD8C"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-406WJTRD8C');
    </script>
    
    <title>Define Operator Computation &#8212; Hidet Documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=ac02cc09edc035673794" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=ac02cc09edc035673794" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794" />
  <script src="../../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=ac02cc09edc035673794"></script>

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'gallery/developer-guides/add-new-operator-compute-definition';</script>
    <link rel="icon" href="../../_static/favicon.svg"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Using Rule-based Scheduling" href="add-new-operator-rule-based.html" />
    <link rel="prev" title="Add New Operator" href="../../how-to-guides/add-new-operator/index.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.svg" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../../_static/logo.svg" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../getting-started/install.html">Installation</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../getting-started/build-from-source.html">Build from source</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../getting-started/quick-start.html">Quick Start</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../tutorials/optimize-pytorch-model.html">Optimize PyTorch Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/optimize-onnx-model.html">Optimize ONNX Model</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Hidet Script</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../hidet-script/index.html">Introduction</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../hidet-script/examples/index.html">Examples</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../hidet-script/0-hello-world.html">Hello World!</a></li>
<li class="toctree-l2"><a class="reference internal" href="../hidet-script/1-scalar-addition.html">Scalar Addition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../hidet-script/2-vector-addition.html">Vector Addition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../hidet-script/3-kernel-functions.html">Kernel Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../hidet-script/4-naive-matmul.html">Naive Matrix Multiplication</a></li>
<li class="toctree-l2"><a class="reference internal" href="../hidet-script/5-efficient-matmul.html">More Efficient Matrix Multiplication</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../hidet-script/reference/index.html">Reference</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../hidet-script/reference/1-type-system.html">Type System</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../hidet-script/reference/2-expression.html">Expressions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../hidet-script/reference/3-statement.html">Statements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../hidet-script/reference/4-function.html">Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../hidet-script/reference/5-module.html">Module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../hidet-script/reference/6-cuda-specific.html">CUDA Specifics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../hidet-script/reference/7-cpu-specific.html">CPU Specifics</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Developer Guide</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../../how-to-guides/add-new-operator/index.html">Add New Operator</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Define Operator Computation</a></li>
<li class="toctree-l2"><a class="reference internal" href="add-new-operator-rule-based.html">Using Rule-based Scheduling</a></li>
<li class="toctree-l2"><a class="reference internal" href="add-new-operator-template-based.html">Using Template-based Scheduling</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="add-operator-resolve-rule.html">Add Operator Resolve Rule</a></li>
<li class="toctree-l1"><a class="reference internal" href="add-subgraph-rewrite-rule.html">Add Sub-Graph Rewrite Rule</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../developer-guides/contributing.html">Contributing</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../notes/operator-cache.html">Operator Cache</a></li>
<li class="toctree-l1"><a class="reference internal" href="../how-to-guides/visualize-flow-graph.html">Visualize Flow Graph</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../python_api/index.html">Python API</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../python_api/root.html">hidet</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../python_api/option.html">hidet.option</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../python_api/cuda.html">hidet.cuda</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../python_api/tensor.html">hidet.Tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../python_api/data_types.html">hidet.dtypes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../python_api/ops/index.html">hidet.ops</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../python_api/graph/index.html">hidet.graph</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../python_api/graph/frontend/index.html">hidet.graph.frontend</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../python_api/graph/frontend/onnx.html">hidet.graph.frontend.onnx</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../python_api/graph/frontend/torch.html">hidet.graph.frontend.torch</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../python_api/graph/transforms/index.html">hidet.graph.transforms</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../python_api/graph/transforms/subgraph_rewrite.html">Sub-graph Rewrite Pass</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../python_api/graph/transforms/resolve_variant.html">Resolve Operator Pass</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../python_api/runtime/index.html">hidet.runtime</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../python_api/utils/index.html">hidet.utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../python_api/testing/index.html">hidet.testing</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../genindex.html">Index</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/hidet-org/hidet" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/gallery/developer-guides/add-new-operator-compute-definition.rst" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.rst</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Define Operator Computation</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#compute-primitives">Compute Primitives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#define-a-computation-task">Define a Computation Task</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#build-and-run-a-task">Build and Run a Task</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#more-examples">More Examples</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reducesum">ReduceSum</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#argmax">ArgMax</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#matmul">MatMul</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#softmax">Softmax</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-gallery-developer-guides-add-new-operator-compute-definition-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="define-operator-computation">
<span id="sphx-glr-gallery-developer-guides-add-new-operator-compute-definition-py"></span><h1>Define Operator Computation<a class="headerlink" href="#define-operator-computation" title="Permalink to this heading"><span>¶</span></a></h1>
<p id="define-computation-task">Each operator takes a list of input tensors and produces a list of output tensors:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">inputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span>
<span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="n">operator</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</pre></div>
</div>
<div class="margin admonition note">
<p class="admonition-title">Note</p>
<p>Our pioneers <a class="reference external" href="https://halide-lang.org/">Halide</a> and <a class="reference external" href="https://tvm.apache.org/">Apache TVM</a> also employ a similar
DSL to define the mathematical definition of an operator.</p>
</div>
<p>The precise mathematical definition of each operator in Hidet is defined through a domain-specific-language (DSL).
In this tutorial, we will show how to define the mathematical definition of a new operator in Hidet using this DSL,
which is defined in the <a class="reference internal" href="../../python_api/ir/compute.html#module-hidet.ir.compute" title="hidet.ir.compute"><code class="xref py py-mod docutils literal notranslate"><span class="pre">hidet.ir.compute</span></code></a> module.</p>
<section id="compute-primitives">
<h2>Compute Primitives<a class="headerlink" href="#compute-primitives" title="Permalink to this heading"><span>¶</span></a></h2>
<p>This module provides compute primitives to define the mathematical computation of an operator:</p>
<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">tensor_input</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span></dt>
<dd><p>The <a class="reference internal" href="../../python_api/ir/compute.html#hidet.ir.compute.tensor_input" title="hidet.ir.compute.tensor_input"><code class="xref py py-func docutils literal notranslate"><span class="pre">tensor_input()</span></code></a> primitive defines a tensor input by specifying the name hint, scalar
data type, and shape of the tensor.</p>
<div class="literal-block-wrapper docutils container" id="id1">
<div class="code-block-caption"><span class="caption-text">Examples</span><a class="headerlink" href="#id1" title="Permalink to this code"><span>¶</span></a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">tensor_input</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tensor_input</span><span class="p">(</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[])</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tensor_input</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float16&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">])</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">compute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fcompute</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Var</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Expr</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span></dt>
<dd><p>The <a class="reference internal" href="../../python_api/ir/compute.html#hidet.ir.compute.compute" title="hidet.ir.compute.compute"><code class="xref py py-func docutils literal notranslate"><span class="pre">compute()</span></code></a> primitive defines a tensor by specifying</p>
<ul class="simple">
<li><p>the name of the tensor, just a hint for what the tensor represents,</p></li>
<li><p>the shape of the tensor, and</p></li>
<li><p>a function that maps an index to the expression that computes the value of the tensor at that index.</p></li>
</ul>
<p>The computation of each element of the tensor is <em>independent</em> with each other and can be computed in parallel.</p>
<div class="literal-block-wrapper docutils container" id="id2">
<div class="code-block-caption"><span class="caption-text">Semantics</span><a class="headerlink" href="#id2" title="Permalink to this code"><span>¶</span></a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># compute primitive</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">compute</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;hint_name&#39;</span><span class="p">,</span>
    <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">n1</span><span class="p">,</span> <span class="n">n2</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">nk</span><span class="p">],</span>
    <span class="n">fcompute</span><span class="o">=</span><span class="k">lambda</span> <span class="n">i1</span><span class="p">,</span> <span class="n">i2</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">ik</span><span class="p">:</span> <span class="n">f</span><span class="p">(</span><span class="n">i1</span><span class="p">,</span> <span class="n">i2</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">ik</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># semantics</span>
<span class="k">for</span> <span class="n">i1</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n1</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">i2</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n2</span><span class="p">):</span>
    <span class="o">...</span>
      <span class="k">for</span> <span class="n">ik</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nk</span><span class="p">):</span>
        <span class="n">out</span><span class="p">[</span><span class="n">i1</span><span class="p">,</span> <span class="n">i2</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">ik</span><span class="p">]</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">i1</span><span class="p">,</span> <span class="n">i2</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">ik</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="margin admonition note">
<p class="admonition-title">Note</p>
<p>In the last example, we used an <a class="reference internal" href="../../python_api/ir/expr.html#hidet.ir.expr.if_then_else" title="hidet.ir.expr.if_then_else"><code class="xref py py-func docutils literal notranslate"><span class="pre">if_then_else()</span></code></a> expression to define a conditional
expression.</p>
</div>
<div class="literal-block-wrapper docutils container" id="id3">
<div class="code-block-caption"><span class="caption-text">Examples</span><a class="headerlink" href="#id3" title="Permalink to this code"><span>¶</span></a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># define an input tensor</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">tensor_input</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>

<span class="c1"># example 1: slice the first column of a</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">compute</span><span class="p">(</span><span class="s1">&#39;slice&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">],</span> <span class="n">fcompute</span><span class="o">=</span><span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>

<span class="c1"># example 2: reverse the rows of matrix a</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">compute</span><span class="p">(</span><span class="s1">&#39;reverse&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="n">fcompute</span><span class="o">=</span><span class="k">lambda</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span> <span class="n">a</span><span class="p">[</span><span class="mi">9</span> <span class="o">-</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span>

<span class="c1"># example 3: add 1 to the diagonal elements of a</span>
<span class="kn">from</span> <span class="nn">hidet.ir.expr</span> <span class="kn">import</span> <span class="n">if_then_else</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">compute</span><span class="p">(</span>
  <span class="n">name</span><span class="o">=</span><span class="s1">&#39;diag_add&#39;</span><span class="p">,</span>
  <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
  <span class="n">fcompute</span><span class="o">=</span><span class="k">lambda</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span> <span class="n">if_then_else</span><span class="p">(</span><span class="n">i</span> <span class="o">==</span> <span class="n">j</span><span class="p">,</span> <span class="n">then_expr</span><span class="o">=</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">else_expr</span><span class="o">=</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">reduce</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">shape</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fcompute</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Var</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Expr</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduce_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sum'</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>The <a class="reference internal" href="../../python_api/ir/compute.html#hidet.ir.compute.reduce" title="hidet.ir.compute.reduce"><code class="xref py py-func docutils literal notranslate"><span class="pre">reduce()</span></code></a> primitive conducts a reduction operation on a domain with the given shape.
It returns a scalar value and can be used in <a class="reference internal" href="../../python_api/ir/compute.html#hidet.ir.compute.compute" title="hidet.ir.compute.compute"><code class="xref py py-func docutils literal notranslate"><span class="pre">compute()</span></code></a> primitive.</p>
<div class="literal-block-wrapper docutils container" id="id4">
<div class="code-block-caption"><span class="caption-text">Semantics</span><a class="headerlink" href="#id4" title="Permalink to this code"><span>¶</span></a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># reduce primitive</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">reduce</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;hint_name&#39;</span><span class="p">,</span>
    <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">n1</span><span class="p">,</span> <span class="n">n2</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">nk</span><span class="p">],</span>
    <span class="n">fcompute</span><span class="o">=</span><span class="k">lambda</span> <span class="n">i1</span><span class="p">,</span> <span class="n">i2</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">ik</span><span class="p">:</span> <span class="n">f</span><span class="p">(</span><span class="n">i1</span><span class="p">,</span> <span class="n">i2</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">ik</span><span class="p">)</span>
    <span class="n">reduce_type</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span> <span class="o">|</span> <span class="s1">&#39;max&#39;</span> <span class="o">|</span> <span class="s1">&#39;min&#39;</span> <span class="o">|</span> <span class="s1">&#39;avg&#39;</span>
<span class="p">)</span>

<span class="c1"># semantics</span>
<span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i1</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n1</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">i2</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n2</span><span class="p">):</span>
    <span class="o">...</span>
      <span class="k">for</span> <span class="n">ik</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nk</span><span class="p">):</span>
        <span class="n">values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">i1</span><span class="p">,</span> <span class="n">i2</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">ik</span><span class="p">))</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">reduce_type</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="literal-block-wrapper docutils container" id="id5">
<div class="code-block-caption"><span class="caption-text">Examples</span><a class="headerlink" href="#id5" title="Permalink to this code"><span>¶</span></a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># define an input tensor</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">tensor_input</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>

<span class="c1"># example 1: sum all elements of a</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">reduce</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="n">fcompute</span><span class="o">=</span><span class="k">lambda</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="n">reduce_type</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span>

<span class="c1"># example 2: sum the first column of a</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">reduce</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">],</span> <span class="n">fcompute</span><span class="o">=</span><span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">reduce_type</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span>

<span class="c1"># example 3: matrix multiplication</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tensor_input</span><span class="p">(</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="n">e</span> <span class="o">=</span> <span class="n">compute</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;e&#39;</span><span class="p">,</span>
    <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
    <span class="n">fcompute</span><span class="o">=</span><span class="k">lambda</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span> <span class="n">reduce</span><span class="p">(</span>
        <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">],</span>
        <span class="n">fcompute</span><span class="o">=</span><span class="k">lambda</span> <span class="n">k</span><span class="p">:</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">b</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span>
        <span class="n">reduce_type</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span>
    <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">arg_reduce</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">extent</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fcompute</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Var</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Expr</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduce_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'max'</span></span></em><span class="sig-paren">)</span></dt>
<dd><p>Similar to <a class="reference internal" href="../../python_api/ir/compute.html#hidet.ir.compute.reduce" title="hidet.ir.compute.reduce"><code class="xref py py-func docutils literal notranslate"><span class="pre">reduce()</span></code></a>, the <a class="reference internal" href="../../python_api/ir/compute.html#hidet.ir.compute.arg_reduce" title="hidet.ir.compute.arg_reduce"><code class="xref py py-func docutils literal notranslate"><span class="pre">arg_reduce()</span></code></a> primitive conducts a
reduction operation on a domain with the given extent. The difference is that it returns the index of the element
that corresponds to the reduction result, instead of the result itself.</p>
<div class="literal-block-wrapper docutils container" id="id6">
<div class="code-block-caption"><span class="caption-text">Semantics</span><a class="headerlink" href="#id6" title="Permalink to this code"><span>¶</span></a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># arg_reduce primitive</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">arg_reduce</span><span class="p">(</span><span class="n">extent</span><span class="p">,</span> <span class="n">fcompute</span><span class="o">=</span><span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">f</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">reduce_type</span><span class="o">=</span><span class="s1">&#39;max&#39;</span> <span class="o">|</span> <span class="s1">&#39;min&#39;</span><span class="p">)</span>

<span class="c1"># semantics</span>
<span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">extent</span><span class="p">):</span>
  <span class="n">values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">index</span> <span class="n">of</span> <span class="n">the</span> <span class="nb">max</span><span class="o">/</span><span class="nb">min</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">values</span>
</pre></div>
</div>
</div>
<div class="literal-block-wrapper docutils container" id="id7">
<div class="code-block-caption"><span class="caption-text">Examples</span><a class="headerlink" href="#id7" title="Permalink to this code"><span>¶</span></a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># define an input tensor</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">tensor_input</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>

<span class="c1"># example: find the index of the max element in each row of a</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">compute</span><span class="p">(</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">10</span><span class="p">],</span> <span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">arg_reduce</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">j</span><span class="p">:</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="n">reduce_type</span><span class="o">=</span><span class="s1">&#39;max&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</dd></dl>

</section>
<section id="define-a-computation-task">
<h2>Define a Computation Task<a class="headerlink" href="#define-a-computation-task" title="Permalink to this heading"><span>¶</span></a></h2>
<p>The computation of each operator can be described as a directed acyclic graph (DAG). The DAG is composed of tensor
nodes. Both <a class="reference internal" href="../../python_api/ir/compute.html#hidet.ir.compute.tensor_input" title="hidet.ir.compute.tensor_input"><code class="xref py py-func docutils literal notranslate"><span class="pre">tensor_input()</span></code></a> and <a class="reference internal" href="../../python_api/ir/compute.html#hidet.ir.compute.compute" title="hidet.ir.compute.compute"><code class="xref py py-func docutils literal notranslate"><span class="pre">compute()</span></code></a> primitives create tensor
nodes. The edges of the DAG are the dependencies between the tensor nodes. Such a DAG is stored in a
<a class="reference internal" href="../../python_api/ir/task.html#hidet.ir.task.Task" title="hidet.ir.task.Task"><code class="xref py py-class docutils literal notranslate"><span class="pre">Task</span></code></a> object.</p>
<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Task</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">TensorNode</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">TensorNode</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<p>Each task has a name, a list of inputs, and a list of outputs, correspongding to the inputs and outputs of the operator.
The following example shows how to create a task.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">demo_task</span><span class="p">():</span>
    <span class="kn">from</span> <span class="nn">hidet.ir.compute</span> <span class="kn">import</span> <span class="n">tensor_input</span><span class="p">,</span> <span class="n">compute</span>
    <span class="kn">from</span> <span class="nn">hidet.ir.task</span> <span class="kn">import</span> <span class="n">Task</span>

    <span class="c1"># define the computation DAG through the compute primitives</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">tensor_input</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">])</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">tensor_input</span><span class="p">(</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">])</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">compute</span><span class="p">(</span><span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">10</span><span class="p">],</span> <span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">i</span><span class="p">)</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">compute</span><span class="p">(</span><span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">10</span><span class="p">],</span> <span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">c</span><span class="p">[</span><span class="mi">9</span> <span class="o">-</span> <span class="n">i</span><span class="p">])</span>
    <span class="n">e</span> <span class="o">=</span> <span class="n">compute</span><span class="p">(</span><span class="s1">&#39;e&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">10</span><span class="p">],</span> <span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

    <span class="c1"># create a task object</span>
    <span class="n">task</span> <span class="o">=</span> <span class="n">Task</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;task&#39;</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">d</span><span class="p">,</span> <span class="n">e</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">task</span><span class="p">)</span>


<span class="n">demo_task</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Task(
  name: task
  parameters:
    a: tensor(float32, [10])
    b: tensor(float32, [10])
    d: tensor(float32, [10])
    e: tensor(float32, [10])
  inputs: [a, b]
  outputs: [d, e]
  computations:
    e: float32[10] where e[v] = (a[v] + b[v])
    c: float32[10] where c[v_1] = (a[v_1] + v_1)
    d: float32[10] where d[v_2] = c[(9 - v_2)]
  attributes: {}
)
</pre></div>
</div>
<p>Its computation DAG can be visualized as follows.</p>
<figure class="align-default" id="id8">
<div class="graphviz"><object data="../../_images/graphviz-b7f2d5746d003c7379dfd1ee2ccd6d040c140648.svg" type="image/svg+xml" class="graphviz">
<p class="warning">digraph {
    // rankdir=LR;
    splines=curved;
    node [
        shape=box, style=&quot;rounded&quot;,
        height=0.4, width=0.6
    ];
    graph [style=&quot;rounded, dashed&quot;]
        subgraph cluster_0 {
            graph [style=&quot;rounded, dashed&quot;, margin=&quot;12&quot;];
            node [group=0];
            label=&quot;Inputs&quot;;
            a [label=&quot;A&quot;];
            b [label=&quot;B&quot;];
        }
        subgraph cluster_1 {
            graph [style=&quot;rounded, dashed&quot;, labelloc=&quot;b&quot;, margin=&quot;15&quot;];
            node [group=1];
            labeljust=&quot;b&quot;;
            d [label=&quot;D&quot;];
            e [label=&quot;E&quot;];
            label=&quot;Outputs&quot;;
        }
        c [label=&quot;C&quot;];
        a -&gt; c -&gt; d
        a -&gt; e
        b -&gt; e
}</p></object></div>
<figcaption>
<p><span class="caption-text">An example of computation DAG. In this example, there are 5 tensor nodes, where node A and B are inputs
and node D and E are outputs. The computation of node C depends on the computation of node A and B.</span><a class="headerlink" href="#id8" title="Permalink to this image"><span>¶</span></a></p>
</figcaption>
</figure>
</section>
<section id="build-and-run-a-task">
<h2>Build and Run a Task<a class="headerlink" href="#build-and-run-a-task" title="Permalink to this heading"><span>¶</span></a></h2>
<p>We provide a driver function <code class="xref py py-func docutils literal notranslate"><span class="pre">hidet.driver.build_task()</span></code> to build a task into callable function. The
<code class="xref py py-func docutils literal notranslate"><span class="pre">build_task()</span></code> function does the following steps to lower the task into a callable function:</p>
<div class="margin admonition note">
<p class="admonition-title">Note</p>
<p>A scheduler is a function that takes a task as input and returns an scheduled tensor program defined in an IRModule.</p>
</div>
<ol class="arabic simple">
<li><p>Dispatch the task to a <strong>scheduler</strong> according to the target device and task.</p></li>
<li><p>The scheduler lowers the task into a tensor program, defined with <code class="xref py py-class docutils literal notranslate"><span class="pre">IRModule</span></code>.</p></li>
<li><p>Lower and optimize the IRModule.</p></li>
<li><p>Code generation that translates the IRModule into the target source code (e.g., <strong>source.cu</strong>).</p></li>
<li><p>Call compiler (e.g., <strong>nvcc</strong>) to compile the source code into a dynamic library (i.e., <strong>lib.so</strong>).</p></li>
<li><p>Load the dynamic library and wrap it to <a class="reference internal" href="../../python_api/runtime/index.html#hidet.runtime.CompiledFunction" title="hidet.runtime.CompiledFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">CompiledFunction</span></code></a> that can be directly called.</p></li>
</ol>
<p>We can define the following function to build and run a task.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>
<span class="kn">import</span> <span class="nn">hidet</span>
<span class="kn">from</span> <span class="nn">hidet.ir.task</span> <span class="kn">import</span> <span class="n">Task</span>


<span class="k">def</span> <span class="nf">run_task</span><span class="p">(</span><span class="n">task</span><span class="p">:</span> <span class="n">Task</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">hidet</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run given task and print inputs and outputs&quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">hidet.runtime</span> <span class="kn">import</span> <span class="n">CompiledTask</span>

    <span class="c1"># build the task</span>
    <span class="n">func</span><span class="p">:</span> <span class="n">CompiledTask</span> <span class="o">=</span> <span class="n">hidet</span><span class="o">.</span><span class="n">drivers</span><span class="o">.</span><span class="n">build_task</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>

    <span class="c1"># run the compiled task</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">func</span><span class="o">.</span><span class="n">run_async</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Task:&#39;</span><span class="p">,</span> <span class="n">task</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Inputs:&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Output:&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
<p>The following code shows how to 1) define the computation, 2) define the task, and 3) build and run the task.</p>
<div class="margin admonition note">
<p class="admonition-title">Note</p>
<p>Please pay attention to the difference between <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code> and
<code class="xref py py-class docutils literal notranslate"><span class="pre">TensorNode</span></code>. The former is a tensor object that can be used to store data and trace the
high-level computation graph of a deep learning model. The latter is a tensor node in the domain-specific language
that is used to describe the computation of a single operator.</p>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">hidet.ir.compute</span> <span class="kn">import</span> <span class="n">tensor_input</span><span class="p">,</span> <span class="n">reduce</span><span class="p">,</span> <span class="n">compute</span><span class="p">,</span> <span class="n">arg_reduce</span><span class="p">,</span> <span class="n">TensorNode</span>



<span class="k">def</span> <span class="nf">add_example</span><span class="p">():</span>
    <span class="n">a</span><span class="p">:</span> <span class="n">TensorNode</span> <span class="o">=</span> <span class="n">tensor_input</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">])</span>
    <span class="n">b</span><span class="p">:</span> <span class="n">TensorNode</span> <span class="o">=</span> <span class="n">tensor_input</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">])</span>
    <span class="n">c</span><span class="p">:</span> <span class="n">TensorNode</span> <span class="o">=</span> <span class="n">compute</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="n">fcompute</span><span class="o">=</span><span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">task</span> <span class="o">=</span> <span class="n">Task</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;add&#39;</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">c</span><span class="p">])</span>
    <span class="n">run_task</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="p">[</span><span class="n">hidet</span><span class="o">.</span><span class="n">randn</span><span class="p">([</span><span class="mi">5</span><span class="p">]),</span> <span class="n">hidet</span><span class="o">.</span><span class="n">randn</span><span class="p">([</span><span class="mi">5</span><span class="p">])])</span>


<span class="n">add_example</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Task: add
Inputs:
Tensor(shape=(5,), dtype=&#39;float32&#39;, device=&#39;cpu&#39;)
[ 0.25 -0.46  1.21 -0.01  0.72]
Tensor(shape=(5,), dtype=&#39;float32&#39;, device=&#39;cpu&#39;)
[-1.65  0.67  0.47 -1.95  0.14]
Output:
Tensor(shape=(5,), dtype=&#39;float32&#39;, device=&#39;cpu&#39;)
[-1.4   0.21  1.67 -1.96  0.86]
</pre></div>
</div>
</section>
<section id="more-examples">
<h2>More Examples<a class="headerlink" href="#more-examples" title="Permalink to this heading"><span>¶</span></a></h2>
<div class="margin admonition tip">
<p class="admonition-title">Tip</p>
<p>All the hidet operators are defined in <code class="xref py py-mod docutils literal notranslate"><span class="pre">hidet.graph.ops</span></code> submodule. And all of existing operators
are defined through the compute primitives described in this tutorial. Feel free to check the source code to learn
more about how to define the computation of different operators.</p>
</div>
<p>At last, we show more examples of using the compute primitives to define operator computation.</p>
<section id="reducesum">
<h3>ReduceSum<a class="headerlink" href="#reducesum" title="Permalink to this heading"><span>¶</span></a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">reduce_sum_example</span><span class="p">():</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">tensor_input</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">compute</span><span class="p">(</span>
        <span class="s1">&#39;b&#39;</span><span class="p">,</span>
        <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span>
        <span class="n">fcompute</span><span class="o">=</span><span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">reduce</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">fcompute</span><span class="o">=</span><span class="k">lambda</span> <span class="n">j</span><span class="p">:</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="n">reduce_type</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">task</span> <span class="o">=</span> <span class="n">Task</span><span class="p">(</span><span class="s1">&#39;reduce_sum&#39;</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">b</span><span class="p">])</span>
    <span class="n">run_task</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="p">[</span><span class="n">hidet</span><span class="o">.</span><span class="n">randn</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">])])</span>


<span class="n">reduce_sum_example</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Task: reduce_sum
Inputs:
Tensor(shape=(4, 3), dtype=&#39;float32&#39;, device=&#39;cpu&#39;)
[[-1.91 -0.52 -0.36]
 [ 0.11  0.95  0.52]
 [-0.34 -1.59  0.26]
 [-1.04 -1.76 -0.2 ]]
Output:
Tensor(shape=(4,), dtype=&#39;float32&#39;, device=&#39;cpu&#39;)
[-2.8   1.58 -1.68 -3.  ]
</pre></div>
</div>
</section>
<section id="argmax">
<h3>ArgMax<a class="headerlink" href="#argmax" title="Permalink to this heading"><span>¶</span></a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">arg_max_example</span><span class="p">():</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">tensor_input</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">compute</span><span class="p">(</span>
        <span class="s1">&#39;b&#39;</span><span class="p">,</span>
        <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span>
        <span class="n">fcompute</span><span class="o">=</span><span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">arg_reduce</span><span class="p">(</span><span class="n">extent</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">fcompute</span><span class="o">=</span><span class="k">lambda</span> <span class="n">j</span><span class="p">:</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="n">reduce_type</span><span class="o">=</span><span class="s1">&#39;max&#39;</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">task</span> <span class="o">=</span> <span class="n">Task</span><span class="p">(</span><span class="s1">&#39;arg_max&#39;</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">b</span><span class="p">])</span>
    <span class="n">run_task</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="p">[</span><span class="n">hidet</span><span class="o">.</span><span class="n">randn</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">])])</span>


<span class="n">arg_max_example</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Task: arg_max
Inputs:
Tensor(shape=(4, 3), dtype=&#39;float32&#39;, device=&#39;cpu&#39;)
[[ 0.41  1.8   0.05]
 [-0.34 -1.74  0.64]
 [-0.44 -0.93  0.13]
 [ 0.25  0.47 -1.07]]
Output:
Tensor(shape=(4,), dtype=&#39;int64&#39;, device=&#39;cpu&#39;)
[1 2 2 1]
</pre></div>
</div>
</section>
<section id="matmul">
<h3>MatMul<a class="headerlink" href="#matmul" title="Permalink to this heading"><span>¶</span></a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">matmul_example</span><span class="p">():</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">tensor_input</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">tensor_input</span><span class="p">(</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">compute</span><span class="p">(</span>
        <span class="s1">&#39;c&#39;</span><span class="p">,</span>
        <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
        <span class="n">fcompute</span><span class="o">=</span><span class="k">lambda</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span> <span class="n">reduce</span><span class="p">(</span>
            <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">fcompute</span><span class="o">=</span><span class="k">lambda</span> <span class="n">k</span><span class="p">:</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">b</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="n">reduce_type</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span>
        <span class="p">),</span>
    <span class="p">)</span>
    <span class="n">task</span> <span class="o">=</span> <span class="n">Task</span><span class="p">(</span><span class="s1">&#39;matmul&#39;</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">c</span><span class="p">])</span>
    <span class="n">run_task</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="p">[</span><span class="n">hidet</span><span class="o">.</span><span class="n">randn</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">hidet</span><span class="o">.</span><span class="n">randn</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">])])</span>


<span class="n">matmul_example</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Task: matmul
Inputs:
Tensor(shape=(3, 3), dtype=&#39;float32&#39;, device=&#39;cpu&#39;)
[[-0.85  0.75 -1.04]
 [-0.52  2.25 -0.63]
 [-0.51  0.39  1.08]]
Tensor(shape=(3, 3), dtype=&#39;float32&#39;, device=&#39;cpu&#39;)
[[-0.8  -0.65  1.15]
 [-0.02  0.25  0.72]
 [-1.47 -1.33 -0.91]]
Output:
Tensor(shape=(3, 3), dtype=&#39;float32&#39;, device=&#39;cpu&#39;)
[[ 2.19  2.12  0.5 ]
 [ 1.29  1.73  1.59]
 [-1.18 -1.   -1.29]]
</pre></div>
</div>
</section>
<section id="softmax">
<h3>Softmax<a class="headerlink" href="#softmax" title="Permalink to this heading"><span>¶</span></a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">softmax_example</span><span class="p">():</span>
    <span class="kn">from</span> <span class="nn">hidet.ir.primitives</span> <span class="kn">import</span> <span class="n">exp</span>

    <span class="n">a</span> <span class="o">=</span> <span class="n">tensor_input</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
    <span class="n">max_val</span> <span class="o">=</span> <span class="n">reduce</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">fcompute</span><span class="o">=</span><span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">reduce_type</span><span class="o">=</span><span class="s1">&#39;max&#39;</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">compute</span><span class="p">(</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">fcompute</span><span class="o">=</span><span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">max_val</span><span class="p">)</span>
    <span class="n">exp_a</span> <span class="o">=</span> <span class="n">compute</span><span class="p">(</span><span class="s1">&#39;exp&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">fcompute</span><span class="o">=</span><span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">exp</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
    <span class="n">exp_sum</span> <span class="o">=</span> <span class="n">reduce</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">fcompute</span><span class="o">=</span><span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">exp_a</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">reduce_type</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span>
    <span class="n">softmax</span> <span class="o">=</span> <span class="n">compute</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">fcompute</span><span class="o">=</span><span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">exp_a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="n">exp_sum</span><span class="p">)</span>

    <span class="n">task</span> <span class="o">=</span> <span class="n">Task</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">softmax</span><span class="p">])</span>
    <span class="n">run_task</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="p">[</span><span class="n">hidet</span><span class="o">.</span><span class="n">randn</span><span class="p">([</span><span class="mi">3</span><span class="p">])])</span>


<span class="n">softmax_example</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Task: softmax
Inputs:
Tensor(shape=(3,), dtype=&#39;float32&#39;, device=&#39;cpu&#39;)
[ 0.58  0.16 -1.86]
Output:
Tensor(shape=(3,), dtype=&#39;float32&#39;, device=&#39;cpu&#39;)
[0.57 0.38 0.05]
</pre></div>
</div>
</section>
</section>
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this heading"><span>¶</span></a></h2>
<p>In this tutorial, we introduced the compute primitives that are used to define the computation of operators in Hidet.
After that, we showed how to wrap the computation DAG into a task and build and run the task. In the next step, we
will show you how to use these compute primitives to define new operators in Hidet.</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 1.148 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-gallery-developer-guides-add-new-operator-compute-definition-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/daf1cfd87892e3c9fd9043ad10877310/add-new-operator-compute-definition.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">add-new-operator-compute-definition.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/d9c0cdd2b656bf8cf5de448a9da6f533/add-new-operator-compute-definition.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">add-new-operator-compute-definition.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="../../how-to-guides/add-new-operator/index.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Add New Operator</p>
      </div>
    </a>
    <a class="right-next"
       href="add-new-operator-rule-based.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Using Rule-based Scheduling</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#compute-primitives">Compute Primitives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#define-a-computation-task">Define a Computation Task</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#build-and-run-a-task">Build and Run a Task</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#more-examples">More Examples</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reducesum">ReduceSum</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#argmax">ArgMax</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#matmul">MatMul</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#softmax">Softmax</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Hidet Team
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023, Hidet Authors.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=ac02cc09edc035673794"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>