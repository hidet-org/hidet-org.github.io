
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-406WJTRD8C"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-406WJTRD8C');
    </script>
    
    <title>Optimize ONNX Model &#8212; Hidet Documentation</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <link rel="shortcut icon" href="../../_static/favicon.svg"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Add New Operator" href="../../how-to-guides/add-new-operator/index.html" />
    <link rel="prev" title="Optimize PyTorch Model" href="optimize-pytorch-model.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.svg" class="logo" alt="logo">
      
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Getting Started
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../getting-started/install.html">
   Installation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../getting-started/build-from-source.html">
     Build from source
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../getting-started/quick-start.html">
   Quick Start
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tutorials
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="optimize-pytorch-model.html">
   Optimize PyTorch Model
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Optimize ONNX Model
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  How-to Guide
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../how-to-guides/add-new-operator/index.html">
   Add New Operator
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../how-to-guides/add-new-operator-compute-definition.html">
     Define Operator Computation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../how-to-guides/add-new-operator-rule-based.html">
     Using Rule-based Scheduling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../how-to-guides/add-new-operator-template-based.html">
     Using Template-based Scheduling
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../how-to-guides/add-operator-resolve-rule.html">
   Add Operator Resolve Rule
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../how-to-guides/add-subgraph-rewrite-rule.html">
   Add Sub-Graph Rewrite Rule
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../how-to-guides/visualize-flow-graph.html">
   Visualize Flow Graph
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Developer Guide
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../developer-guides/contributing.html">
   Contributing
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../developer-guides/hidet-script/index.html">
   Hidet Script
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../developer-guides/hidet-script-dynamic-kernel.html">
     Writing Dynamic kernel
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Notes
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../notes/operator-cache.html">
   Operator Cache
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Reference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../python_api/index.html">
   Python API
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../python_api/root.html">
     hidet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../python_api/option.html">
     hidet.option
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../python_api/driver.html">
     hidet.driver
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../python_api/cuda.html">
     hidet.cuda
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../python_api/tensor.html">
     hidet.Tensor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../python_api/data_types.html">
     hidet.dtypes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../python_api/ops/index.html">
     hidet.ops
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../python_api/ir/index.html">
     hidet.ir
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../python_api/ir/type.html">
       hidet.ir.type
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../python_api/ir/expr.html">
       hidet.ir.expr
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../python_api/ir/stmt.html">
       hidet.ir.stmt
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../python_api/ir/func.html">
       hidet.ir.func
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../python_api/ir/compute.html">
       hidet.ir.compute
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../python_api/ir/task.html">
       hidet.ir.task
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../python_api/graph/index.html">
     hidet.graph
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
    <label for="toctree-checkbox-6">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../python_api/graph/frontend/index.html">
       hidet.graph.frontend
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
      <label for="toctree-checkbox-7">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../python_api/graph/frontend/onnx.html">
         hidet.graph.frontend.onnx
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../python_api/graph/frontend/torch.html">
         hidet.graph.frontend.torch
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../python_api/graph/transforms/index.html">
       hidet.graph.transforms
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
      <label for="toctree-checkbox-8">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../python_api/graph/transforms/subgraph_rewrite.html">
         Sub-graph Rewrite Pass
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../python_api/graph/transforms/resolve_variant.html">
         Resolve Operator Pass
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../python_api/runtime/index.html">
     hidet.runtime
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../python_api/utils/index.html">
     hidet.utils
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../python_api/testing/index.html">
     hidet.testing
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../genindex.html">
   Index
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            <a href=/netron target=_blank>Customized Netron</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>
<a href="https://github.com/hidet-org/hidet"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="bottom"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/gallery/tutorials/run-onnx-model.rst.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.rst</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#preparation-of-onnx-model">
   Preparation of ONNX model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-the-onnx-model-with-hidet">
   Load the onnx model with Hidet
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#imperatively-run-the-model">
   Imperatively run the model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#trace-the-model-and-run">
   Trace the model and run
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optimize-flowgraph">
   Optimize FlowGraph
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Optimize ONNX Model</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#preparation-of-onnx-model">
   Preparation of ONNX model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-the-onnx-model-with-hidet">
   Load the onnx model with Hidet
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#imperatively-run-the-model">
   Imperatively run the model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#trace-the-model-and-run">
   Trace the model and run
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optimize-flowgraph">
   Optimize FlowGraph
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-gallery-tutorials-run-onnx-model-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="optimize-onnx-model">
<span id="run-onnx-model-with-hidet"></span><span id="sphx-glr-gallery-tutorials-run-onnx-model-py"></span><h1>Optimize ONNX Model<a class="headerlink" href="#optimize-onnx-model" title="Permalink to this headline"><span>¶</span></a></h1>
<p>This tutorial walks through the steps to run a model in <a class="reference external" href="https://onnx.ai/">ONNX format</a> with Hidet.
The ResNet50 onnx model exported from PyTorch model zoo would be used as an example.</p>
<section id="preparation-of-onnx-model">
<h2>Preparation of ONNX model<a class="headerlink" href="#preparation-of-onnx-model" title="Permalink to this headline"><span>¶</span></a></h2>
<p>We first export the pretrained resnet50 model from torchvision model zoo to an onnx model, using
<a class="reference external" href="https://pytorch.org/docs/stable/onnx.html#torch.onnx.export" title="(in PyTorch v1.13)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.onnx.export()</span></code></a>. After exporting, there will be a file named <code class="docutils literal notranslate"><span class="pre">resnet50.onnx</span></code>
under current working directory.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="c1"># the path to save the onnx model</span>
<span class="n">onnx_path</span> <span class="o">=</span> <span class="s1">&#39;./resnet50.onnx&#39;</span>

<span class="c1"># load pretrained resnet50 and create a random input</span>
<span class="n">torch_model</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/hub.html#torch.hub.load" title="torch.hub.load" class="sphx-glr-backref-module-torch-hub sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">hub</span><span class="o">.</span><span class="n">load</span></a><span class="p">(</span>
    <span class="s1">&#39;pytorch/vision:v0.9.0&#39;</span><span class="p">,</span> <span class="s1">&#39;resnet50&#39;</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
<span class="n">torch_model</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.cuda" title="torch.nn.Module.cuda" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">torch_model</span><span class="o">.</span><span class="n">cuda</span></a><span class="p">()</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch_data</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">])</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="c1"># export the pytorch model to onnx model &#39;resnet50.onnx&#39;</span>
<a href="https://pytorch.org/docs/stable/onnx.html#torch.onnx.export" title="torch.onnx.export" class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">export</span></a><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">torch_model</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch_data</span></a><span class="p">,</span>
    <span class="n">f</span><span class="o">=</span><span class="n">onnx_path</span><span class="p">,</span>
    <span class="n">input_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">],</span>
    <span class="n">output_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;output&#39;</span><span class="p">],</span>
    <span class="n">dynamic_axes</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;data&#39;</span><span class="p">:</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">},</span> <span class="s1">&#39;output&#39;</span><span class="p">:</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">}},</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1">: </span><span class="si">{:.1f}</span><span class="s1"> MiB&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">onnx_path</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">getsize</span><span class="p">(</span><span class="n">onnx_path</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="mi">20</span><span class="p">)))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>======= Diagnostic Run torch.onnx.export version 2.0.0.dev20221219+cu116 =======
verbose: False, log level: Level.ERROR
======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================

./resnet50.onnx: 97.4 MiB
</pre></div>
</div>
<p>Before going further, we first measure the latency of reset50 directly using PyTorch for inference.
The <a class="reference internal" href="../../python_api/utils/index.html#hidet.utils.benchmark_func" title="hidet.utils.benchmark_func"><code class="xref py py-func docutils literal notranslate"><span class="pre">benchmark_func()</span></code></a> function runs the given function multiple times to
get the median latency.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">hidet.utils</span> <span class="kn">import</span> <span class="n">benchmark_func</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;PyTorch: </span><span class="si">{:.3f}</span><span class="s1"> ms&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">benchmark_func</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">torch_model</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch_data</span></a><span class="p">))))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>PyTorch: 2.328 ms
</pre></div>
</div>
</section>
<section id="load-the-onnx-model-with-hidet">
<h2>Load the onnx model with Hidet<a class="headerlink" href="#load-the-onnx-model-with-hidet" title="Permalink to this headline"><span>¶</span></a></h2>
<p>To run the onnx model, we should first load the model with <a class="reference internal" href="../../python_api/graph/frontend/onnx.html#hidet.graph.frontend.from_onnx" title="hidet.graph.frontend.from_onnx"><code class="xref py py-func docutils literal notranslate"><span class="pre">hidet.graph.frontend.from_onnx()</span></code></a> function by giving
the path to the onnx model. This function returns callable object, which applies all operators in the onnx model to
the input argument and returns the output tensor(s). The onnx model can be dynamic-shaped (e.g., in this example, the
batch size is dynamic).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">hidet</span>

<span class="c1"># load onnx model &#39;resnet50.onnx&#39;</span>
<span class="n">hidet_onnx_module</span> <span class="o">=</span> <span class="n">hidet</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">frontend</span><span class="o">.</span><span class="n">from_onnx</span><span class="p">(</span><span class="n">onnx_path</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Input names:&#39;</span><span class="p">,</span> <span class="n">hidet_onnx_module</span><span class="o">.</span><span class="n">input_names</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Output names: &#39;</span><span class="p">,</span> <span class="n">hidet_onnx_module</span><span class="o">.</span><span class="n">output_names</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Input names: [&#39;data&#39;]
Output names:  [&#39;output&#39;]
</pre></div>
</div>
</section>
<section id="imperatively-run-the-model">
<h2>Imperatively run the model<a class="headerlink" href="#imperatively-run-the-model" title="Permalink to this headline"><span>¶</span></a></h2>
<p>To run the model, we first create a hidet tensor from torch tensor with <a class="reference internal" href="../../python_api/root.html#hidet.from_torch" title="hidet.from_torch"><code class="xref py py-func docutils literal notranslate"><span class="pre">hidet.from_torch()</span></code></a>. We directly
call <code class="docutils literal notranslate"><span class="pre">hidet_onnx_module</span></code> to apply the operators in loaded onnx model to the given input tensor and get the output
tensor.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># create a hidet tensor from pytorch tensor.</span>
<span class="n">data</span><span class="p">:</span> <span class="n">hidet</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">hidet</span><span class="o">.</span><span class="n">from_torch</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch_data</span></a><span class="p">)</span>

<span class="c1"># apply the operators in onnx model to given &#39;data&#39; input tensor</span>
<span class="n">output</span><span class="p">:</span> <span class="n">hidet</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">hidet_onnx_module</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># check the output of hidet with pytorch</span>
<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch_output</span></a> <span class="o">=</span> <span class="n">torch_model</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch_data</span></a><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
<a href="https://numpy.org/doc/stable/reference/generated/numpy.testing.assert_allclose.html#numpy.testing.assert_allclose" title="numpy.testing.assert_allclose" class="sphx-glr-backref-module-numpy-testing sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span></a><span class="p">(</span>
    <span class="n">actual</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">desired</span><span class="o">=</span><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch_output</span></a><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-2</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="trace-the-model-and-run">
<h2>Trace the model and run<a class="headerlink" href="#trace-the-model-and-run" title="Permalink to this headline"><span>¶</span></a></h2>
<p>A more efficient way to run the model is to first trace the execution and get the static computation graph of the deep
learning model. We can use <a class="reference internal" href="../../python_api/root.html#hidet.symbol_like" title="hidet.symbol_like"><code class="xref py py-func docutils literal notranslate"><span class="pre">hidet.symbol_like()</span></code></a> to create a symbol tensor. We can get the symbol tensor output by
running the model with the symbol tensor as input. The output is a symbol tensor that contains all information of how
it is derived. We can use <a class="reference internal" href="../../python_api/root.html#hidet.trace_from" title="hidet.trace_from"><code class="xref py py-func docutils literal notranslate"><span class="pre">hidet.trace_from()</span></code></a> to create the static computation graph from the symbol output
tensor. In hidet, we use <a class="reference internal" href="../../python_api/graph/index.html#hidet.graph.FlowGraph" title="hidet.graph.FlowGraph"><code class="xref py py-class docutils literal notranslate"><span class="pre">hidet.graph.FlowGraph</span></code></a> to represent such a computation graph, and it is also the
basic unit of graph-level optimizations.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">symbol_data</span> <span class="o">=</span> <span class="n">hidet</span><span class="o">.</span><span class="n">symbol_like</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">symbol_output</span> <span class="o">=</span> <span class="n">hidet_onnx_module</span><span class="p">(</span><span class="n">symbol_data</span><span class="p">)</span>
<span class="n">graph</span><span class="p">:</span> <span class="n">hidet</span><span class="o">.</span><span class="n">FlowGraph</span> <span class="o">=</span> <span class="n">hidet</span><span class="o">.</span><span class="n">trace_from</span><span class="p">(</span><span class="n">symbol_output</span><span class="p">)</span>
</pre></div>
</div>
<p>We can directly call the flow graph to run it. A more efficient way is to create a
CUDA Graph according to the flow graph and run the CUDA Graph.</p>
<div class="margin admonition note">
<p class="admonition-title">Note</p>
<p>The <a class="reference external" href="https://developer.nvidia.com/blog/cuda-graphs/">CUDA Graph</a> is a more efficient
way to submit workload to NVIDIA GPU, it eliminates most of the framework-side overhead.</p>
</div>
<p>We use <a class="reference internal" href="../../python_api/graph/index.html#hidet.graph.FlowGraph.cuda_graph" title="hidet.graph.FlowGraph.cuda_graph"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cuda_graph()</span></code></a> method of a <a class="reference internal" href="../../python_api/graph/index.html#hidet.graph.FlowGraph" title="hidet.graph.FlowGraph"><code class="xref py py-class docutils literal notranslate"><span class="pre">FlowGraph</span></code></a> to create a
<a class="reference internal" href="../../python_api/cuda.html#hidet.cuda.graph.CudaGraph" title="hidet.cuda.graph.CudaGraph"><code class="xref py py-class docutils literal notranslate"><span class="pre">CudaGraph</span></code></a>.
Then, we use <a class="reference internal" href="../../python_api/cuda.html#hidet.cuda.graph.CudaGraph.run" title="hidet.cuda.graph.CudaGraph.run"><code class="xref py py-meth docutils literal notranslate"><span class="pre">run()</span></code></a> method to run the cuda graph.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">bench_hidet_graph</span><span class="p">(</span><span class="n">graph</span><span class="p">:</span> <span class="n">hidet</span><span class="o">.</span><span class="n">FlowGraph</span><span class="p">):</span>
    <span class="n">cuda_graph</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">cuda_graph</span><span class="p">()</span>
    <span class="p">(</span><span class="n">output</span><span class="p">,)</span> <span class="o">=</span> <span class="n">cuda_graph</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">data</span><span class="p">])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.testing.assert_allclose.html#numpy.testing.assert_allclose" title="numpy.testing.assert_allclose" class="sphx-glr-backref-module-numpy-testing sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span></a><span class="p">(</span>
        <span class="n">actual</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
        <span class="n">desired</span><span class="o">=</span><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch_output</span></a><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
        <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span>
        <span class="n">atol</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  Hidet: </span><span class="si">{:.3f}</span><span class="s1"> ms&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">benchmark_func</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">cuda_graph</span><span class="o">.</span><span class="n">run</span><span class="p">())))</span>


<span class="n">bench_hidet_graph</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Hidet: 6.196 ms
</pre></div>
</div>
</section>
<section id="optimize-flowgraph">
<h2>Optimize FlowGraph<a class="headerlink" href="#optimize-flowgraph" title="Permalink to this headline"><span>¶</span></a></h2>
<p>To optimize the model, we set the level of operator schedule space to 2 with <a class="reference internal" href="../../python_api/option.html#hidet.option.search_space" title="hidet.option.search_space"><code class="xref py py-func docutils literal notranslate"><span class="pre">hidet.option.search_space()</span></code></a>. We also
conduct graph level optimizations with <a class="reference internal" href="../../python_api/graph/index.html#hidet.graph.optimize" title="hidet.graph.optimize"><code class="xref py py-func docutils literal notranslate"><span class="pre">hidet.graph.optimize()</span></code></a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the search space level for kernel tuning. By default, the search space level is 0, which means no kernel tuning.</span>
<span class="c1"># There are three choices: 0, 1, and 2. The higher the level, the better performance but the longer compilation time.</span>
<span class="n">hidet</span><span class="o">.</span><span class="n">option</span><span class="o">.</span><span class="n">search_space</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># optimize the flow graph, such as operator fusion</span>
<span class="k">with</span> <span class="n">hidet</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">PassContext</span><span class="p">()</span> <span class="k">as</span> <span class="n">ctx</span><span class="p">:</span>
    <span class="n">ctx</span><span class="o">.</span><span class="n">save_graph_instrument</span><span class="p">(</span><span class="s1">&#39;./outs/graphs&#39;</span><span class="p">)</span>
    <span class="n">graph_opt</span><span class="p">:</span> <span class="n">hidet</span><span class="o">.</span><span class="n">FlowGraph</span> <span class="o">=</span> <span class="n">hidet</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>

<span class="n">bench_hidet_graph</span><span class="p">(</span><span class="n">graph_opt</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Hidet: 2.005 ms
</pre></div>
</div>
</section>
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline"><span>¶</span></a></h2>
<p>Hidet is a DNN inference framework that accepts ONNX model. It conducts both graph-level and operator-level
optimizations. We follow the following steps to run an ONNX model in Hidet:</p>
<ol class="arabic simple">
<li><p>Load the model with <a class="reference internal" href="../../python_api/graph/frontend/onnx.html#hidet.graph.frontend.from_onnx" title="hidet.graph.frontend.from_onnx"><code class="xref py py-func docutils literal notranslate"><span class="pre">hidet.graph.frontend.from_onnx()</span></code></a>.</p></li>
<li><p>Run the model with symbolic inputs, and use <a class="reference internal" href="../../python_api/root.html#hidet.trace_from" title="hidet.trace_from"><code class="xref py py-func docutils literal notranslate"><span class="pre">hidet.trace_from()</span></code></a> to create the <a class="reference internal" href="../../python_api/graph/index.html#hidet.graph.FlowGraph" title="hidet.graph.FlowGraph"><code class="xref py py-class docutils literal notranslate"><span class="pre">hidet.graph.FlowGraph</span></code></a>.</p></li>
<li><p>Create a <a class="reference internal" href="../../python_api/cuda.html#hidet.cuda.graph.CudaGraph" title="hidet.cuda.graph.CudaGraph"><code class="xref py py-class docutils literal notranslate"><span class="pre">hidet.cuda.graph.CudaGraph</span></code></a> using <a class="reference internal" href="../../python_api/graph/index.html#hidet.graph.FlowGraph.cuda_graph" title="hidet.graph.FlowGraph.cuda_graph"><code class="xref py py-func docutils literal notranslate"><span class="pre">hidet.graph.FlowGraph.cuda_graph()</span></code></a>.</p></li>
<li><p>Run the cuda graph.</p></li>
</ol>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 1 minutes  8.782 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-gallery-tutorials-run-onnx-model-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/cd480f4cd22f016c656022f5dfda4d9c/run-onnx-model.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">run-onnx-model.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/467c47b6a756372480e913dae064b675/run-onnx-model.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">run-onnx-model.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="optimize-pytorch-model.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Optimize PyTorch Model</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../../how-to-guides/add-new-operator/index.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Add New Operator</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Hidet Team<br/>
  
      &copy; Copyright 2022, Hidet Authors.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>