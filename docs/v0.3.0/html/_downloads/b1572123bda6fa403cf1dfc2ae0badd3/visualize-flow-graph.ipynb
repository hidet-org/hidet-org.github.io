{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Visualize Flow Graph\n\nVisualization is a key component of a machine learning tool to allow us have a better understanding of the model.\n\nWe customized the popular [Netron](https://github.com/lutzroeder/netron) viewer to visualize the flow graph of a\nhidet model. The customized Netron viewer can be found at [here](/netron), you can also find a link on the\nbottom of the documentation side bar.\n\nIn this tutorial, we will show you how to visualize the flow graph of a model.\n\n## Define model\n\nWe first define a model with a self-attention layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import math\nimport hidet\nfrom hidet import Tensor\nfrom hidet.graph import nn, ops\n\n\nclass SelfAttention(nn.Module):\n    def __init__(self, hidden_size=768, num_attention_heads=12):\n        super().__init__()\n        self.num_attention_heads = num_attention_heads\n        self.attention_head_size = hidden_size // num_attention_heads\n\n        self.query_layer = nn.Linear(hidden_size, hidden_size)\n        self.key_layer = nn.Linear(hidden_size, hidden_size)\n        self.value_layer = nn.Linear(hidden_size, hidden_size)\n\n    def transpose_for_scores(self, x: Tensor) -> Tensor:\n        batch_size, seq_length, hidden_size = x.shape\n        x = x.reshape([batch_size, seq_length, self.num_attention_heads, self.attention_head_size])\n        x = x.rearrange([[0, 2], [1], [3]])\n        return x  # [batch_size * num_attention_heads, seq_length, attention_head_size]\n\n    def forward(self, hidden_states: Tensor, attention_mask: Tensor):\n        batch_size, seq_length, _ = hidden_states.shape\n        query = self.transpose_for_scores(self.query_layer(hidden_states))\n        key = self.transpose_for_scores(self.key_layer(hidden_states))\n        value = self.transpose_for_scores(self.value_layer(hidden_states))\n        attention_scores = ops.matmul(query, ops.transpose(key, [-1, -2])) / math.sqrt(\n            self.attention_head_size\n        )\n        attention_scores = attention_scores + attention_mask\n        attention_probs = ops.softmax(attention_scores, axis=-1)\n        context = ops.matmul(attention_probs, value)\n        context = context.reshape(\n            [batch_size, self.num_attention_heads, seq_length, self.attention_head_size]\n        )\n        context = context.rearrange([[0], [2], [1, 3]])\n        return context\n\n\nmodel = SelfAttention()\nprint(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate flow graph\nThen we generate the flow graph of the model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph = model.flow_graph_for(\n    inputs=[hidet.randn([1, 128, 768]), hidet.ones([1, 128], dtype='int32')]\n)\nprint(graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dump netron graph\nTo visualize the flow graph, we need to dump the graph structure to a json file using\n:py:func:`hidet.utils.netron.dump` function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from hidet.utils import netron\n\nwith open('attention-graph.json', 'w') as f:\n    netron.dump(graph, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Above code will generate a json file named ``attention-graph.json``.\n\nYou can download the generated json file\n:download:`attention-graph.json <../../../../gallery/how-to-guides/attention-graph.json>`\nand open it with the [customized Netron viewer](/netron).\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize optimization intermediate graphs\n\nHidet also provides a way to visualize the intermediate graphs of the optimization passes.\n\nTo get the json files for the intermediate graphs, we need to add an instrument that dumps the graph in the\npass context before optimize it. We can use\n:py:meth:`PassContext.save_graph_instrument() <hidet.graph.transforms.PassContext.save_graph_instrument>`\nmethod to do that.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with hidet.graph.PassContext() as ctx:\n    # print the time cost of each pass\n    ctx.profile_pass_instrument(print_stdout=True)\n\n    # save the intermediate graph of each pass to './outs' directory\n    ctx.save_graph_instrument(out_dir='./outs')\n\n    # run the optimization passes\n    graph_opt = hidet.graph.optimize(graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Above code will generate a directory named ``outs`` that contains the json files for the intermediate graphs.\nThe optimized graph:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(graph_opt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\nThis tutorial shows how to visualize the flow graph of a model and the intermediate graphs of the optimization passes.\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}