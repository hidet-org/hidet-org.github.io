
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-406WJTRD8C"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-406WJTRD8C');
    </script>
    
    <title>Visualize Flow Graph &#8212; Hidet Documentation</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <link rel="shortcut icon" href="../../_static/favicon.svg"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Contributing" href="../../developer-guides/contributing.html" />
    <link rel="prev" title="Add Sub-Graph Rewrite Rule" href="add-subgraph-rewrite-rule.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.svg" class="logo" alt="logo">
      
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Getting Started
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../getting-started/install.html">
   Installation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../getting-started/build-from-source.html">
     Build from source
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../getting-started/quick-start.html">
   Quick Start
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tutorials
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/optimize-pytorch-model.html">
   Optimize PyTorch Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/run-onnx-model.html">
   Optimize ONNX Model
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  How-to Guide
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../how-to-guides/add-new-operator/index.html">
   Add New Operator
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="add-new-operator-compute-definition.html">
     Define Operator Computation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="add-new-operator-rule-based.html">
     Using Rule-based Scheduling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="add-new-operator-template-based.html">
     Using Template-based Scheduling
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="add-operator-resolve-rule.html">
   Add Operator Resolve Rule
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="add-subgraph-rewrite-rule.html">
   Add Sub-Graph Rewrite Rule
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Visualize Flow Graph
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Developer Guide
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../developer-guides/contributing.html">
   Contributing
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../developer-guides/hidet-script/index.html">
   Hidet Script
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../developer-guides/hidet-script-dynamic-kernel.html">
     Writing Dynamic kernel
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Notes
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../notes/operator-cache.html">
   Operator Cache
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Reference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../python_api/index.html">
   Python API
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../python_api/root.html">
     hidet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../python_api/option.html">
     hidet.option
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../python_api/driver.html">
     hidet.driver
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../python_api/cuda.html">
     hidet.cuda
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../python_api/tensor.html">
     hidet.Tensor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../python_api/data_types.html">
     hidet.dtypes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../python_api/ops/index.html">
     hidet.ops
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../python_api/ir/index.html">
     hidet.ir
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../python_api/ir/type.html">
       hidet.ir.type
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../python_api/ir/expr.html">
       hidet.ir.expr
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../python_api/ir/stmt.html">
       hidet.ir.stmt
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../python_api/ir/func.html">
       hidet.ir.func
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../python_api/ir/compute.html">
       hidet.ir.compute
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../python_api/ir/task.html">
       hidet.ir.task
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../python_api/graph/index.html">
     hidet.graph
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
    <label for="toctree-checkbox-6">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../python_api/graph/frontend/index.html">
       hidet.graph.frontend
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
      <label for="toctree-checkbox-7">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../python_api/graph/frontend/onnx.html">
         hidet.graph.frontend.onnx
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../python_api/graph/frontend/torch.html">
         hidet.graph.frontend.torch
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../python_api/graph/transforms/index.html">
       hidet.graph.transforms
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
      <label for="toctree-checkbox-8">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../python_api/graph/transforms/subgraph_rewrite.html">
         Sub-graph Rewrite Pass
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../python_api/graph/transforms/resolve_variant.html">
         Resolve Operator Pass
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../python_api/runtime/index.html">
     hidet.runtime
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../python_api/utils/index.html">
     hidet.utils
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../python_api/testing/index.html">
     hidet.testing
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../genindex.html">
   Index
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            <a href=/netron target=_blank>Customized Netron</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>
<a href="https://github.com/hidet-org/hidet"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="bottom"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/gallery/how-to-guides/visualize-flow-graph.rst.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.rst</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#define-model">
   Define model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#generate-flow-graph">
   Generate flow graph
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dump-netron-graph">
   Dump netron graph
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualize-optimization-intermediate-graphs">
   Visualize optimization intermediate graphs
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Visualize Flow Graph</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#define-model">
   Define model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#generate-flow-graph">
   Generate flow graph
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dump-netron-graph">
   Dump netron graph
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualize-optimization-intermediate-graphs">
   Visualize optimization intermediate graphs
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-gallery-how-to-guides-visualize-flow-graph-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="visualize-flow-graph">
<span id="sphx-glr-gallery-how-to-guides-visualize-flow-graph-py"></span><h1>Visualize Flow Graph<a class="headerlink" href="#visualize-flow-graph" title="Permalink to this headline"><span>¶</span></a></h1>
<p>Visualization is a key component of a machine learning tool to allow us have a better understanding of the model.</p>
<p>We customized the popular <a class="reference external" href="https://github.com/lutzroeder/netron">Netron</a> viewer to visualize the flow graph of a
hidet model. The customized Netron viewer can be found at <a class="reference external" href="/netron">here</a>, you can also find a link on the
bottom of the documentation side bar.</p>
<p>In this tutorial, we will show you how to visualize the flow graph of a model.</p>
<section id="define-model">
<h2>Define model<a class="headerlink" href="#define-model" title="Permalink to this headline"><span>¶</span></a></h2>
<p>We first define a model with a self-attention layer.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">hidet</span>
<span class="kn">from</span> <span class="nn">hidet</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">hidet.graph</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">ops</span>


<span class="k">class</span> <span class="nc">SelfAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">num_attention_heads</span><span class="o">=</span><span class="mi">12</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">=</span> <span class="n">num_attention_heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention_head_size</span> <span class="o">=</span> <span class="n">hidden_size</span> <span class="o">//</span> <span class="n">num_attention_heads</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">query_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">key_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">transpose_for_scores</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_length</span><span class="p">,</span> <span class="n">hidden_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
            <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_head_size</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">rearrange</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]])</span>
        <span class="k">return</span> <span class="n">x</span>  <span class="c1"># [batch_size * num_attention_heads, seq_length, attention_head_size]</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_states</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_length</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">query</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_for_scores</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">query_layer</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">))</span>
        <span class="n">key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_for_scores</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">key_layer</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">))</span>
        <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_for_scores</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">value_layer</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">))</span>
        <span class="n">attention_scores</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">]))</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">attention_head_size</span>
        <span class="p">)</span>
        <span class="n">attention_scores</span> <span class="o">=</span> <span class="n">attention_scores</span> <span class="o">+</span> <span class="n">attention_mask</span>
        <span class="n">attention_probs</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attention_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">attention_probs</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
            <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span><span class="p">,</span> <span class="n">seq_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_head_size</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">rearrange</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
        <span class="k">return</span> <span class="n">context</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">SelfAttention</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>SelfAttention(
  (query_layer): Linear(in_features=768, out_features=768)
  (key_layer): Linear(in_features=768, out_features=768)
  (value_layer): Linear(in_features=768, out_features=768)
)
</pre></div>
</div>
</section>
<section id="generate-flow-graph">
<h2>Generate flow graph<a class="headerlink" href="#generate-flow-graph" title="Permalink to this headline"><span>¶</span></a></h2>
<p>Then we generate the flow graph of the model.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">graph</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">flow_graph_for</span><span class="p">(</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">hidet</span><span class="o">.</span><span class="n">randn</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">768</span><span class="p">]),</span> <span class="n">hidet</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">128</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;int32&#39;</span><span class="p">)]</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Graph(x: float32[1, 128, 768], x_1: int32[1, 128]){
  c = Constant(float32[768, 768])
  c_1 = Constant(float32[768])
  c_2 = Constant(float32[768, 768])
  c_3 = Constant(float32[768])
  c_4 = Constant(float32[768, 768])
  c_5 = Constant(float32[768])
  x_2: float32[1, 128, 768] = Matmul(x, c)
  x_3: float32[1, 128, 768] = Add(x_2, c_1)
  x_4: float32[1, 128, 12, 64] = Reshape(x_3, shape=[1, 128, 12, 64])
  x_5: float32[12, 128, 64] = Rearrange(x_4, plan=[[0, 2], [1], [3]])
  x_6: float32[1, 128, 768] = Matmul(x, c_2)
  x_7: float32[1, 128, 768] = Add(x_6, c_3)
  x_8: float32[1, 128, 12, 64] = Reshape(x_7, shape=[1, 128, 12, 64])
  x_9: float32[12, 128, 64] = Rearrange(x_8, plan=[[0, 2], [1], [3]])
  x_10: float32[12, 64, 128] = PermuteDims(x_9, axes=[0, 2, 1])
  x_11: float32[12, 128, 128] = Matmul(x_5, x_10)
  x_12: float32[12, 128, 128] = DivideScalar(x_11, scalar=8.0f)
  x_13: float32[12, 128, 128] = Add(x_12, x_1)
  x_14: float32[12, 128, 128] = Softmax(x_13, axis=2)
  x_15: float32[1, 128, 768] = Matmul(x, c_4)
  x_16: float32[1, 128, 768] = Add(x_15, c_5)
  x_17: float32[1, 128, 12, 64] = Reshape(x_16, shape=[1, 128, 12, 64])
  x_18: float32[12, 128, 64] = Rearrange(x_17, plan=[[0, 2], [1], [3]])
  x_19: float32[12, 128, 64] = Matmul(x_14, x_18)
  x_20: float32[1, 12, 128, 64] = Reshape(x_19, shape=[1, 12, 128, 64])
  x_21: float32[1, 128, 768] = Rearrange(x_20, plan=[[0], [2], [1, 3]])
  return x_21
}
</pre></div>
</div>
</section>
<section id="dump-netron-graph">
<h2>Dump netron graph<a class="headerlink" href="#dump-netron-graph" title="Permalink to this headline"><span>¶</span></a></h2>
<p>To visualize the flow graph, we need to dump the graph structure to a json file using
<code class="xref py py-func docutils literal notranslate"><span class="pre">hidet.utils.netron.dump()</span></code> function.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">hidet.utils</span> <span class="kn">import</span> <span class="n">netron</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;attention-graph.json&#39;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">netron</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</pre></div>
</div>
<p>Above code will generate a json file named <code class="docutils literal notranslate"><span class="pre">attention-graph.json</span></code>.</p>
<p>You can download the generated json file
<a class="reference download internal" download="" href="../../_downloads/41cd3ca6b07c0a1d62500aeb9005a246/attention-graph.json"><code class="xref download docutils literal notranslate"><span class="pre">attention-graph.json</span></code></a>
and open it with the <a class="reference external" href="/netron">customized Netron viewer</a>.</p>
</section>
<section id="visualize-optimization-intermediate-graphs">
<h2>Visualize optimization intermediate graphs<a class="headerlink" href="#visualize-optimization-intermediate-graphs" title="Permalink to this headline"><span>¶</span></a></h2>
<p>Hidet also provides a way to visualize the intermediate graphs of the optimization passes.</p>
<p>To get the json files for the intermediate graphs, we need to add an instrument that dumps the graph in the
pass context before optimize it. We can use
<code class="xref py py-meth docutils literal notranslate"><span class="pre">PassContext.save_graph_instrument()</span></code>
method to do that.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">hidet</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">PassContext</span><span class="p">()</span> <span class="k">as</span> <span class="n">ctx</span><span class="p">:</span>
    <span class="c1"># print the time cost of each pass</span>
    <span class="n">ctx</span><span class="o">.</span><span class="n">profile_pass_instrument</span><span class="p">(</span><span class="n">print_stdout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># save the intermediate graph of each pass to &#39;./outs&#39; directory</span>
    <span class="n">ctx</span><span class="o">.</span><span class="n">save_graph_instrument</span><span class="p">(</span><span class="n">out_dir</span><span class="o">=</span><span class="s1">&#39;./outs&#39;</span><span class="p">)</span>

    <span class="c1"># run the optimization passes</span>
    <span class="n">graph_opt</span> <span class="o">=</span> <span class="n">hidet</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>    FoldConstantPass started...
    FoldConstantPass 0.007 seconds
 SubgraphRewritePass started...
 SubgraphRewritePass 1.634 seconds
AutoMixPrecisionPass started...
AutoMixPrecisionPass 0.006 seconds
 SubgraphRewritePass started...
 SubgraphRewritePass 0.013 seconds
  ResolveVariantPass started...
  ResolveVariantPass 1.635 seconds
    FuseOperatorPass started...
    FuseOperatorPass 0.030 seconds
EliminateBarrierPass started...
EliminateBarrierPass 0.006 seconds
</pre></div>
</div>
<p>Above code will generate a directory named <code class="docutils literal notranslate"><span class="pre">outs</span></code> that contains the json files for the intermediate graphs.
The optimized graph:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">graph_opt</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Graph(x: float32[1, 128, 768], x_1: int32[1, 128]){
  c = Constant(float32[4, 192, 2304])
  c_1 = Constant(float32[2304])
  x_2: float32[1, 4, 128, 2304] = FusedBatchMatmul(c, x, fused_graph=FlowGraph(Reshape, Rearrange, BatchMatmul, Reshape), anchor=2)
  x_3: float32[1, 128, 2304] = FusedReduceSum(x_2, c_1, fused_graph=FlowGraph(ReduceSum, Add), anchor=0)
  x_4: float32[12, 8, 128, 128] = FusedBatchMatmul(x_3, fused_graph=FlowGraph(StridedSlice, Reshape, Rearrange, Reshape, Rearrange, StridedSlice, Reshape, Rearrange, PermuteDims, Reshape, Rearrange, BatchMatmul, Reshape), anchor=11)
  x_5: float32[12, 128, 128] = FusedReduceSum(x_4, x_1, fused_graph=FlowGraph(ReduceSum, DivideScalar, Add), anchor=0)
  x_6: float32[96, 128, 16] = FusedSoftmax(x_5, fused_graph=FlowGraph(Softmax, Reshape, Rearrange), anchor=0)
  x_7: float32[12, 8, 128, 64] = FusedBatchMatmul(x_6, x_3, fused_graph=FlowGraph(StridedSlice, Reshape, Rearrange, Reshape, Rearrange, BatchMatmul, Reshape), anchor=5)
  x_8: float32[1, 128, 768] = FusedReduceSum(x_7, fused_graph=FlowGraph(ReduceSum, Reshape, Rearrange), anchor=0)
  return x_8
}
</pre></div>
</div>
<p>The dumped netron graphs that can be visualized:</p>
<p><a class="reference download internal" download="" href="../../_downloads/2d18d0b686fbeaf056c713febf76abf3/1_FoldConstantPass.json"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">1_FoldConstantPass.json</span></code></a></p>
<p><a class="reference download internal" download="" href="../../_downloads/3626f85698c146d1152ba614bb32bfb0/2_SubgraphRewritePass.json"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">2_PatternTransformPass.json</span></code></a></p>
<p><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">4_ResolveVariantPass.json</span></code></p>
<p><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">5_FuseOperatorPass.json</span></code></p>
</section>
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline"><span>¶</span></a></h2>
<p>This tutorial shows how to visualize the flow graph of a model and the intermediate graphs of the optimization passes.</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  7.397 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-gallery-how-to-guides-visualize-flow-graph-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/7571d7f85637a51cfcfd336aba85e8ca/visualize-flow-graph.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">visualize-flow-graph.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/b1572123bda6fa403cf1dfc2ae0badd3/visualize-flow-graph.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">visualize-flow-graph.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="add-subgraph-rewrite-rule.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Add Sub-Graph Rewrite Rule</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../../developer-guides/contributing.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Contributing</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Hidet Team<br/>
  
      &copy; Copyright 2023, Hidet Authors.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>