{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Using Rule-based Scheduling\n\nIn the previous tutorial, we have learned how to define the computation using compute primitives and wrap it into a\n:py:class:`~hidet.ir.task.Task`. In this tutorial, we will learn how to add an operator (i.e.,\n:py:class:`~hidet.graph.Operator`) with given computation definition, and use hidet's provided rule-based scheduler to\nautomatically schedule the computation into a tensor program.\n\n## Three steps to define a new operator\n\nThere are three steps to define a new operator in Hidet.\n\n1. Define the computation task class by inheriting :py:class:`~hidet.ir.task.Task`.\n2. Define the operator class by inheriting :py:class:`~hidet.graph.Operator`.\n3. Define a function to create the operator instance.\n\n## Batch Matrix Multiplication Example\n\nWe will take the batch matrix multiplication as an example to illustrate the three steps.\n\n### 1. Define the computation task class\n\nWe define the computation task class **BatchMatmulTask** by inheriting :py:class:`~hidet.ir.task.Task` class. The\n**BatchMatmulTask** class's constructor function takes two arguments, **a** and **b** that are the input tensor nodes\nof the batch matrix multiplication.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from hidet.ir.compute import TensorNode, compute, reduce\nfrom hidet.ir.task import Task\n\n\nclass BatchMatmulTask(Task):\n    def __init__(self, a: TensorNode, b: TensorNode):\n        # get the input sizes\n        batch_size, m_size, k_size = a.const_shape()\n        batch_size, k_size, n_size = b.const_shape()\n\n        # define the computation\n        c = compute(\n            name='c',\n            shape=[batch_size, m_size, n_size],\n            fcompute=lambda p, i, j: reduce(\n                shape=[k_size],\n                fcompute=lambda k: a[p, i, k] * b[p, k, j],\n                reduce_type='sum',\n            ),\n        )\n\n        # call the parent class constructor to initialize the task\n        super().__init__(\n            name='batch_matmul',  # the name of the task\n            inputs=[a, b],  # the input tensor nodes\n            outputs=[c],  # the output tensor nodes\n        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Define the operator class\nOur next step is to define the operator class **BatchMatmulOp** by inheriting :py:class:`~hidet.graph.Operator` class.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from hidet.graph import Operator, Tensor\nfrom hidet.graph.ops.definitions.utils import input_like\n\n\nclass BatchMatmulOp(Operator):\n    def __init__(self, a: Tensor, b: Tensor):\n        # call the parent class constructor to initialize the operator\n        super().__init__(\n            inputs=[a, b],  # the input tensors\n            attributes={},\n            task=BatchMatmulTask(  # the task of the operator\n                # create tensor nodes (TensorNode) with the same shape and dtype as the tensors (Tensor)\n                input_like(a, 'a'),\n                input_like(b, 'b'),\n            ),\n        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Define a function to create the operator instance\nWe define a function **batch_matmul** to create the operator instance **BatchMatmulOp** and return the output tensor.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def batch_matmul(a: Tensor, b: Tensor) -> Tensor:\n    # get_output(0) returns the first output tensor of the operator\n    return BatchMatmulOp(a, b).get_output(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Use the defined operator\nThe new operator has no difference with the hidet provided operators, as we define hidet operators in the same way.\nFor example, when we optimize the flow graph, this new operator can also fuse surrounding operators.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import hidet\n\n\ndef demo_usage():\n    a = hidet.randn([2, 2, 3])\n    b = hidet.randn([2, 3, 2])\n    c = batch_matmul(a, b)\n    print(a)\n    print(b)\n    print(c)\n\n\ndemo_usage()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Two Scheduling Machanisms\nWe only define the computation of the operator, and leave the scheduling to the rule-based scheduler provided by\nhidet. We call this method of scheduling as **rule-based scheduling**. Most hidet operators are using the same\nrule-based scheduler as we used in this example. Our experience shows that the rule-based\nscheduler can achieve good performance for operators that do not have large amount of reduction. However, for\noperators like matrix multiplication, convolution, etc., the rule-based scheduler may not be able to achieve the\nbest performance as it does not use shared memory to cache the data loading. Thus, hidet also provides another\nscheduling mechanism, the **template-based scheduling**.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\nIn this tutorial, we have learned how to define a new operator with given computation definition, and use hidet's\nprovided rule-based scheduler to automatically schedule the computation into a tensor program. In the next tutorial,\nwe will learn how to use the template-based scheduling to achieve better performance.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}